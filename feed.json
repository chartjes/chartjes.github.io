
                                                                        
[
    {
        "author": null,
        "categories": [
            "tools"
        ],
        "content": "<h2 id=\"grumpiness-and-neovim\">Grumpiness and NeoVim<\/h2>\n\n<p>I have been a <a href=\"https:\/\/vim.org\">Vim<\/a> user since the early 2000's.\nSomeone who worked in the same building as me and was also a fellow\nLinux user (this was before I had bought my first Macbook) got\nto talking with me as I struggled to figure out <a href=\"https:\/\/www.gnu.org\/software\/emacs\/\">Emacs<\/a>\nsuggested I sit with him for a little bit as he showed me how to\nuse Vim. Still not sure to this day why it clicked with me but I\nhave been using it ever since.<\/p>\n\n<p>In the past few years I have changed which version of Vim I am\nusing and switched to <a href=\"https:\/\/neovim.io\/\">NeoVim<\/a>.<\/p>\n\n<p>Now, to be transparent, these days I use <a href=\"https:\/\/www.jetbrains.com\/phpstorm\/\">PhpStorm<\/a>\nas my main PHP programming tool and use NeoVim for pretty much everything\nelse. I do pay for PhpStorm because I think it's important to encourage the creation\nof tools for the programming languages I use. If I was still doing a lot of\nPython work, I'd be paying for <a href=\"https:\/\/www.jetbrains.com\/pycharm\/\">PyCharm<\/a>.\nI had really good experiences with it while at Mozilla.<\/p>\n\n<p>Anyway, I still like to keep up with what is going on in the NeoVim \"community\"\nand I am happy to see a vibrant group of people creating plugins and\nsharing their knowledge. I wanted to give things with NeoVim and PHP another\nspin so it was time to go look at my current setup.<\/p>\n\n<h2 id=\"why-do-all-this%3F\">Why do all this?<\/h2>\n\n<p>My goal is to have a Vim experience that matches the way I currently work.\nI've been using Vim for so long that there is lots of muscle memory and\nI usually enable \"Vim mode\" in any tools I use. Editing things a \"modal way\"\nhas become my default and any tools that don't support doing things that\nway slow me down immensely.<\/p>\n\n<p>So, what do I want out of my NeoVim setup.<\/p>\n\n<ul>\n<li>works well with the languages I will use<\/li>\n<li>allows me to quickly find files<\/li>\n<li>allows me to quickly find source definitions<\/li>\n<li>allows me to quickly find places where code is used<\/li>\n<\/ul>\n\n<p>Now, of course, PhpStorm does all this but also carries a lot of extra\nfunctionality around with it. Which is fine! But in an era where the tools\nwe use on desktop operating systems get bigger and bigger and consume more\nand more resources, I find something appealing in using tools that take up\nas few resources as possible.<\/p>\n\n<p>I did an older post on my old blog from about a year ago so I will\nfollow the same structure but I noticed some changes. I'll be going\nthrough my current NeoVim config and filling things in as we go<\/p>\n\n<pre><code>set nocompatible\nsyntax on \nset encoding=utf8\nfiletype off\n\n\" Load our plugins\nlua require('plugins')\n<\/code><\/pre>\n\n<p>I am using as much <a href=\"https:\/\/www.lua.org\">Lua<\/a> as I can within NeoVim.\nThe first few steps here are pretty much standard:<\/p>\n\n<ul>\n<li>you always turn \"no compatible\" off otherwise lots of things break<\/li>\n<li>I want syntax highlighting by default<\/li>\n<li>I want things to be UTF8<\/li>\n<li><p>I am going to define my own behaviour for how I want NeoVim to\nhandle filetypes<\/p>\n\n<h2 id=\"plugins\">Plugins<\/h2>\n\n<p>My list of plugins:<\/p>\n\n<p>```\nreturn require('packer').startup(function()\nuse 'wbthomason\/packer.nvim'\nuse 'neovim\/nvim-lspconfig'<\/p>\n\n<p>-- General plugins\nuse 'dracula\/vim'\nuse 'junegunn\/vim-easy-align'\nuse {\n    'nvim-treesitter\/nvim-treesitter',\n    run = ':TSUpdate'\n}\nuse 'onsails\/lspkind-nvim'\nuse 'vim-vdebug\/vdebug'<\/p>\n\n<p>-- See the git status of the current line in the gutter\nuse 'airblade\/vim-gitgutter'<\/p>\n\n<p>--  PHP plugins\nuse 'tpope\/vim-dispatch'\nuse 'StanAngeloff\/php.vim'\nuse 'stephpy\/vim-php-cs-fixer'\nuse 'jwalton512\/vim-blade'\nuse 'noahfrederick\/vim-laravel'<\/p>\n\n<p>-- Help for vim-laravel\nuse 'tpope\/vim-projectionist'\nuse 'noahfrederick\/vim-composer'<\/p>\n\n<p>-- Respect .editorconfig files for a project\nuse 'editorconfig\/editorconfig-vim'<\/p>\n\n<p>-- Telescope support\nuse 'nvim-lua\/plenary.nvim'\nuse 'nvim-telescope\/telescope.nvim'\nuse 'sharkdp\/fd'\nuse {'nvim-telescope\/telescope-fzf-native.nvim', run = 'make' }<\/p>\n\n<p>-- LSP support for Typescropt\nuse 'jose-elias-alvarez\/nvim-lsp-ts-utils'<\/p>\n\n<p>-- nvim-cmp support\nuse 'hrsh7th\/nvim-cmp'\nuse 'hrsh7th\/cmp-nvim-lsp'\nuse 'saadparwaiz1\/cmp_luasnip'\nuse 'L3MON4D3\/LuaSnip'<\/p><\/li>\n<\/ul>\n\n<p>end)<\/p>\n\n<pre><code><br \/>I am using [Packer](https:\/\/github.com\/wbthomason\/packer.nvim) to\nhandle installing all my packages. I have commented in places where I\nfelt that things were not clear, but I guess some further explanations\ncouldn't hurt.\n\n* I use the [Dracula](https:\/\/draculatheme.com\/vim) theme\n* I use [vim-easy-align](https:\/\/github.com\/junegunn\/vim-easy-align)\n  to make it easier to line up blocks of code\n* [vim-gitgutter](https:\/\/github.com\/airblade\/vim-gitgutter) shows me\n  which lines have changed from Git's perspective\n* I like to respect the\n  [EditorConfig](https:\/\/github.com\/editorconfig\/editorconfig-vim)\n  settings for a project if they exist\n* [Telescope](https:\/\/github.com\/nvim-telescope\/telescope.nvim) \nforms the basis for a lot of fuzzy find functionality\n* I use [nvim-cmp](https:\/\/github.com\/hrsh7th\/nvim-cmp) as my\n  completion engine (and it plays nicely with Intelephense)\n\n## More NeoVim Settings\n\n<\/code><\/pre>\n\n<p>\" Do smart autoindenting\nset smartindent\nset autoindent<\/p>\n\n<p>\" I like linenumbers, thanks\nset number<\/p>\n\n<p>\" set search case to a good configuration http:\/\/vim.wikia.com\/wiki\/Searching\nset ignorecase\nset smartcase<\/p>\n\n<p>\" I like pretty colours in my terminal\nset t_Co=256<\/p>\n\n<p>\" Let's get some good colours in our terminal\nlet $NVM_TUI_ENABLE_TRUE_COLOR=1\nset termguicolors\ncolor dracula<\/p>\n\n<p>\" We want to use ripgrep for any grep commands\nset grepprg='rg'<\/p>\n\n<p>\" Basic configuration options\nset tabstop=4\nset shiftwidth=4\nset softtabstop=0\nset smarttab\nset expandtab\nset wildmenu\nset wildmode=list:longest,full\nset ttyfast\nset showmatch\nset hlsearch\nset incsearch\nset backspace=indent,eol,start<\/p>\n\n<p>\" Make sure we are using the version of Python we want\nlet g:python3_host_prog = \"\/opt\/homebrew\/bin\/python3\"<\/p>\n\n<p>\" We always want to use UTF-8\nset encoding=UTF-8\nset fileencoding=UTF-8<\/p>\n\n<pre><code><br \/>A lot of what is up there is fairly straightforward when it comes to\nVim\/NeoVim, so I am not going to go over a lot of them.\n\n## LSP Configuration\n\nThis is the critical piece for me -- supporting different languages\nmakes NeoVim so versatile.\n\nIn my config I have these two lines:\n\n<\/code><\/pre>\n\n<p>lua require('lsp-config')\nlua require('nvm-cmp')<\/p>\n\n<pre><code><br \/>and these handle my languages and making sure autocompletion behaves\nas I expect.\n\n```lua\n--- Configuration for LSP, formatters, and linters.\nlocal nvim_lsp = require(\"lspconfig\")\n\n-- short cut methods.\nlocal t = function(str)\n  return vim.api.nvim_replace_termcodes(str, true, true, true)\nend\n\nlocal opts = { noremap=true, silent=true }\nvim.api.nvim_set_keymap('n', '&lt;space&gt;e', '&lt;cmd&gt;lua vim.diagnostic.open_float()&lt;CR&gt;', opts)\nvim.api.nvim_set_keymap('n', '[d', '&lt;cmd&gt;lua vim.diagnostic.goto_prev()&lt;CR&gt;', opts)\nvim.api.nvim_set_keymap('n', ']d', '&lt;cmd&gt;lua vim.diagnostic.goto_next()&lt;CR&gt;', opts)\nvim.api.nvim_set_keymap('n', '&lt;space&gt;q', '&lt;cmd&gt;lua vim.diagnostic.setloclist()&lt;CR&gt;', opts)\nvim.api.nvim_set_keymap('n', '&lt;space&gt;f', '&lt;cmd&gt;lua vim.lsp.buf.formatting()&lt;CR&gt;', opts)\n\nlocal on_attach = function(client, bufnr)\n  -- Enable completion triggered by &lt;c-x&gt;&lt;c-o&gt;\n  vim.api.nvim_buf_set_option(bufnr, 'omnifunc', 'v:lua.vim.lsp.omnifunc')\n\n  -- Mappings.\n  -- See `:help vim.lsp.*` for documentation on any of the below functions\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'gD', '&lt;cmd&gt;lua vim.lsp.buf.declaration()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'gd', '&lt;cmd&gt;lua vim.lsp.buf.definition()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'K', '&lt;cmd&gt;lua vim.lsp.buf.hover()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'gi', '&lt;cmd&gt;lua vim.lsp.buf.implementation()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;C-k&gt;', '&lt;cmd&gt;lua vim.lsp.buf.signature_help()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;wa', '&lt;cmd&gt;lua vim.lsp.buf.add_workspace_folder()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;wr', '&lt;cmd&gt;lua vim.lsp.buf.remove_workspace_folder()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;wl', '&lt;cmd&gt;lua print(vim.inspect(vim.lsp.buf.list_workspace_folders()))&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;D', '&lt;cmd&gt;lua vim.lsp.buf.type_definition()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;rn', '&lt;cmd&gt;lua vim.lsp.buf.rename()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;ca', '&lt;cmd&gt;lua vim.lsp.buf.code_action()&lt;CR&gt;', opts)\n  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'gr', '&lt;cmd&gt;lua vim.lsp.buf.references()&lt;CR&gt;', opts)\nend\n\n-- PHP\nnvim_lsp.intelephense.setup {\n    cmd = { \"intelephense\", \"--stdio\" },\n    filetypes = { \"php\" },\n}\n\n--- Linter setup\nlocal filetypes = {\n  typescript = \"eslint\",\n  typescriptreact = \"eslint\",\n  php = {\"phpcs\", \"psalm\"},\n}\n\nlocal linters = {\n  phpcs = {\n    command = \"vendor\/bin\/phpcs\",\n    sourceName = \"phpcs\",\n    debounce = 300,\n    rootPatterns = {\"composer.lock\", \"vendor\", \".git\"},\n    args = {\"--report=emacs\", \"-s\", \"-\"},\n    offsetLine = 0,\n    offsetColumn = 0,\n    sourceName = \"phpcs\",\n    formatLines = 1,\n    formatPattern = {\n      \"^.*:(\\\\d+):(\\\\d+):\\\\s+(.*)\\\\s+-\\\\s+(.*)(\\\\r|\\\\n)*$\",\n      {\n        line = 1,\n        column = 2,\n        message = 4,\n        security = 3\n      }\n    },\n    securities = {\n      error = \"error\",\n      warning = \"warning\",\n    },\n    requiredFiles = {\"vendor\/bin\/phpcs\"}\n  },\n  psalm = {\n    command = \".\/vendor\/bin\/psalm\",\n    sourceName = \"psalm\",\n    debounce = 100,\n    rootPatterns = {\"composer.lock\", \"vendor\", \".git\"},\n    args = {\"--output-format=emacs\", \"--no-progress\"},\n    offsetLine = 0,\n    offsetColumn = 0,\n    sourceName = \"psalm\",\n    formatLines = 1,\n    formatPattern = {\n      \"^[^ =]+ =(\\\\d+) =(\\\\d+) =(.*)\\\\s-\\\\s(.*)(\\\\r|\\\\n)*$\",\n      {\n        line = 1,\n        column = 2,\n        message = 4,\n        security = 3\n      }\n    },\n    securities = {\n      error = \"error\",\n      warning = \"warning\"\n    },\n    requiredFiles = {\"vendor\/bin\/psalm\"}\n  }\n}\n\nnvim_lsp.diagnosticls.setup {\n  on_attach = on_attach,\n  filetypes = vim.tbl_keys(filetypes),\n  init_options = {\n    filetypes = filetypes,\n    linters = linters,\n  },\n}\n<\/code><\/pre>\n\n<p>A lot of what is in here I simple stole from other people's\nconfigurations but I think most of it should be straightforward to\nfigure out.<\/p>\n\n<p>Some highlights from my perspective:<\/p>\n\n<ul>\n<li>you pick which language servers to care about<\/li>\n<li>you map functionality to existing Vim bindings so, again, it behaves\nas expected<\/li>\n<\/ul>\n\n<p>Here is what I have for getting the autocompletion engine working:<\/p>\n\n<pre><code class=\"lua\">local capabilities = vim.lsp.protocol.make_client_capabilities()\n\nlocal lspconfig = require('lspconfig')\n\n-- Enable some language servers with the additional completion capabilities offered by nvim-cmp\nlocal servers = { 'intelephense', 'tsserver' }\nfor _, lsp in ipairs(servers) do\n  lspconfig[lsp].setup {\n    -- on_attach = my_custom_on_attach,\n    capabilities = capabilities,\n  }\nend\n\n-- luasnip setup\nlocal luasnip = require 'luasnip'\n\n-- nvim-cmp setup\nlocal cmp = require 'cmp'\ncmp.setup {\n  snippet = {\n    expand = function(args)\n      require('luasnip').lsp_expand(args.body)\n    end,\n  },\n  mapping = {\n    ['&lt;C-p&gt;'] = cmp.mapping.select_prev_item(),\n    ['&lt;C-n&gt;'] = cmp.mapping.select_next_item(),\n    ['&lt;C-d&gt;'] = cmp.mapping.scroll_docs(-4),\n    ['&lt;C-f&gt;'] = cmp.mapping.scroll_docs(4),\n    ['&lt;C-Space&gt;'] = cmp.mapping.complete(),\n    ['&lt;C-e&gt;'] = cmp.mapping.close(),\n    ['&lt;CR&gt;'] = cmp.mapping.confirm {\n      behavior = cmp.ConfirmBehavior.Replace,\n      select = true,\n    },\n    ['&lt;Tab&gt;'] = function(fallback)\n      if cmp.visible() then\n        cmp.select_next_item()\n      elseif luasnip.expand_or_jumpable() then\n        luasnip.expand_or_jump()\n      else\n        fallback()\n      end\n    end,\n    ['&lt;S-Tab&gt;'] = function(fallback)\n      if cmp.visible() then\n        cmp.select_prev_item()\n      elseif luasnip.jumpable(-1) then\n        luasnip.jump(-1)\n      else\n        fallback()\n      end\n    end,\n  },\n  sources = {\n    { name = 'nvim_lsp' },\n    { name = 'luasnip' },\n  },\n}\n<\/code><\/pre>\n\n<p>Again, more mapping of existing keys to get the plugin to behave as\nexpected. This sort of thing lies at the very heart of how Vim\/NeoVim\nplugins do so much work -- they literally alter how the application\nbehaves by overriding things. Perhaps this is actually a form of\nmonkey patching? TIME IS A CIRCLE.<\/p>\n\n<h2 id=\"key-mappings\">Key Mappings<\/h2>\n\n<pre><code class=\"vim\">\" ------------------------------------------------------------------------------\n\" # Mappings\n\" ------------------------------------------------------------------------------\n\" # All of your mappings go in this file! Don't worry about your mappings\n\" # being separate from related config. Sourcery provides mappings to\n\" # easily jump between plugin definitions, mappings, and configs.\n\" #\n\" # More info: https:\/\/github.com\/jesseleite\/vim-sourcery#jumping-between-files\n\n\n\" ------------------------------------------------------------------------------\n\" # Example\n\" ------------------------------------------------------------------------------\n\n\" easily switch between vsplit windows\nmap &lt;Leader&gt;j &lt;C-w&gt;j\nmap &lt;Leader&gt;k &lt;C-w&gt;k\nmap &lt;Leader&gt;h &lt;c-w&gt;h\nmap &lt;Leader&gt;l &lt;c-w&gt;l\n\n\" Remove highlighing of search terms\nnnoremap &lt;leader&gt;&lt;space&gt; :nohlsearch&lt;CR&gt;\n\n\" Mappings for EasyAlign\nxmap ga &lt;Plug&gt;(EasyAlign)\nnmap ga &lt;Plug&gt;(EasyAlign)\n\n\" Use &lt;Tab&gt; and &lt;S-Tab&gt; to navigate through popup menu\ninoremap &lt;expr&gt; &lt;Tab&gt;   pumvisible() ? \"\\&lt;C-n&gt;\" : \"\\&lt;Tab&gt;\"\ninoremap &lt;expr&gt; &lt;S-Tab&gt; pumvisible() ? \"\\&lt;C-p&gt;\" : \"\\&lt;S-Tab&gt;\"\n\n\" Telescope Lua mappings\nnnoremap &lt;leader&gt;ff &lt;cmd&gt;lua require('telescope.builtin').find_files()&lt;cr&gt;\nnnoremap &lt;leader&gt;fg &lt;cmd&gt;lua require('telescope.builtin').live_grep()&lt;cr&gt;\nnnoremap &lt;leader&gt;fb &lt;cmd&gt;lua require('telescope.builtin').buffers()&lt;cr&gt;\nnnoremap &lt;leader&gt;fh &lt;cmd&gt;lua require('telescope.builtin').help_tags()&lt;cr&gt;\nnnoremap &lt;leader&gt;fr &lt;cmd&gt;lua require('telescope.builtin').lsp_references()&lt;cr&gt;\nnnoremap &lt;leader&gt;fd &lt;cmd&gt;lua require('telescope.builtin').lsp_definitions()&lt;cr&gt;\nnnoremap &lt;leader&gt;ft &lt;cmd&gt;lua require('telescope.builtin').lsp_type_definitions()&lt;cr&gt;\n<\/code><\/pre>\n\n<p>No Vim setup is complete without mapping and re-mapping keys in\nVim. The list above mostly focuses on making Telescope friendlier to\nuse.<\/p>\n\n<p>So there you have it -- this is my current NeoVim setup. It is more\nthan sufficient for me to do daily PHP development work. What are some\nother things I am looking to integrate into my setup?<\/p>\n\n<ul>\n<li>Make it easier to use <a href=\"https:\/\/xdebug.org\">XDebug<\/a><\/li>\n<li>More refactoring tools (I understand Intelephense can help but I\nhave also experimented with\n<a href=\"https:\/\/github.com\/phpactor\/phpactor\">Phpactor<\/a><\/li>\n<\/ul>\n\n<p>As always, I continue to tweak my configuration as I evaluate new\ntools or discover new ways of completing old tasks. I hope you find my\nsetup useful.<\/p>\n",
        "date": "2022-12-13T00:00:00+00:00",
        "site": null,
        "tags": null,
        "title": "Current NeoVim setup",
        "uri": "https:\/\/grumpy-learning.com\/blog\/2022\/12\/13\/current-neovim-setup\/"
    },
    {
        "author": null,
        "categories": [
            "PHP",
            "testing"
        ],
        "content": "<p>One of the reasons many experienced developers encourage the concept of\n\"decoupling your code\" is so that it makes testing your code straightforward.\nI wanted to share an example of how I went about writing some tests for\nsome code that I had refactored from being a tangled spaghetti-like mess.<\/p>\n\n<p>Here is the code I am looking at, written targeting PHP 8.1.<\/p>\n\n<pre><code class=\"php\">&lt;?php\ndeclare(strict_types=1);\n\nnamespace Webreg\\Query;\n\nuse Slim\\Psr7\\Response;\nuse Slim\\Psr7\\Request;\nuse Twig\\Environment;\nuse Webreg\\Repository\\GameRepository;\nuse Webreg\\ViewModel\\Rotations;\n\nfinal class RotationManagementQuery\n{\n    public function __construct(\n        private Environment $twig,\n        private GameRepository $gameRepository,\n        private Rotations $rotations\n    ) {}\n\n    public function __invoke(Request $request): Response\n    {\n        $params = $request-&gt;getQueryParams();\n        $maxWeek = $this-&gt;gameRepository-&gt;getMaxWeek();\n        $week = (isset($params['week'])) ? (int) $params['week'] : $maxWeek;\n        $rotations = $this-&gt;rotations-&gt;getAllByWeek($week);\n        $response = new Response(200, null);\n        $response-&gt;getBody()-&gt;write($this-&gt;twig-&gt;render('rotations\/management.twig', [\n            'current_week' =&gt; $week,\n            'rotations' =&gt; $rotations,\n        ]));\n\n        return $response;\n    }\n}\n<\/code><\/pre>\n\n<p>I am using <a href=\"https:\/\/www.martinfowler.com\/bliki\/CQRS.html\">Command Query Responsibility Segregation<\/a> in\nthis application's architecture, and this bit of code is a Query that will\nretrieve a collection of pitchers who will be starting for baseball\nteams in my simulation baseball league for a particular week.<\/p>\n\n<p>In following some rules for decoupling, you can see some of the\nfollowing decisions had been made:<\/p>\n\n<ul>\n<li>not extending off of a base class<\/li>\n<li>all dependencies are injected at run time<\/li>\n<li>single-method for the class<\/li>\n<\/ul>\n\n<h2 id=\"identifying-dependencies\">Identifying Dependencies<\/h2>\n\n<p>So what are the dependencies I will need?<\/p>\n\n<ul>\n<li>a <a href=\"https:\/\/twig.symfony.com\">Twig<\/a> object<\/li>\n<li>a <a href=\"https:\/\/martinfowler.com\/eaaCatalog\/repository.html\">repository<\/a> object for retrieving data<\/li>\n<li>a <a href=\"https:\/\/martinfowler.com\/eaaDev\/PresentationModel.html\">view model<\/a> for presenting the data<\/li>\n<li>an object that contains the HTTP <a href=\"https:\/\/www.php-fig.org\/psr\/psr-7\/\">request<\/a><\/li>\n<\/ul>\n\n<p>In the old architecture, I was creating those dependencies deep inside the \"business logic\"\nand therefore it was very hard to write anything other than some kind of \"check\nthe HTML output\" type of test. Ironically that is what the new test does as well but\nthis sort of decoupled architecture leads to a much more straightforward test.<\/p>\n\n<h2 id=\"identifying-output\">Identifying Output<\/h2>\n\n<p>In these tests, I wanted to make sure that if I had at least one rotation\nstored in the database for a particular week, when the page renders I should\nsee that rotation in the output somewhere.<\/p>\n\n<h2 id=\"test-skeleton\">Test Skeleton<\/h2>\n\n<p>As always, I break out the <a href=\"http:\/\/wiki.c2.com\/?ArrangeActAssert\">Arrange-Act-Assert<\/a> pattern\nto create the skeleton of the test:<\/p>\n\n<pre><code class=\"php\">    \/** @test *\/\n    public function it_returns_expected_rotation(): void\n    {\n        \/\/ Arrange\n\n        \/\/ Act\n\n        \/\/ Assert\n        self::fail();\n    }\n<\/code><\/pre>\n\n<p>Remember, you always want to start with a failing test.<\/p>\n\n<h2 id=\"arranging-our-dependencies\">Arranging our dependencies<\/h2>\n\n<p>These days I try and use the fewest number of <a href=\"https:\/\/phpunit.readthedocs.io\/en\/9.5\/test-doubles.html\">test doubles<\/a>\nin my test scenarios. Given the dependencies I needed,\nI was going to need three \"fake\" dependencies, configured\nto provide only the implementation details required to make\nthe scenario work.<\/p>\n\n<p>I don't want to get into a longer discussion on the use of\ntest doubles except to say that the decoupling strategy\nI am using will minimize the chances that any doubles drift\nfrom how the code is actually implemented.<\/p>\n\n<p>Trust me, I do this for a living!<\/p>\n\n<pre><code class=\"php\">    \/** @test *\/\n    public function it_returns_expected_rotation(): void\n    {\n        \/\/ Arrange\n        $loader = new FilesystemLoader(__DIR__ . '\/..\/..\/templates\/');\n        $twig = new Environment($loader);\n\n        $gamesRepo = $this-&gt;createMock(GameRepository::class);\n        $gamesRepo-&gt;expects($this-&gt;once())\n            -&gt;method('getMaxWeek')\n            -&gt;willReturn(1);\n\n        $testRotation = new ArrayCollection();\n        $testRotation-&gt;add([\n            'franchise_id' =&gt; 1,\n            'ibl' =&gt; 'MAD',\n            'rotation' =&gt; 'One, Two, Three'\n        ]);\n\n        $viewModel = $this-&gt;createMock(RotationsUsingDoctrine::class);\n        $viewModel-&gt;expects($this-&gt;once())\n            -&gt;method('getAllByWeek')\n            -&gt;willReturn($testRotation);\n\n        $request = $this-&gt;createMock(Request::class);\n        $request-&gt;expects($this-&gt;once())\n            -&gt;method('getQueryParams')\n            -&gt;willReturn(['week' =&gt; 1]);\n\n        \/\/ Act\n\n        \/\/ Assert\n        self::fail();\n    }\n<\/code><\/pre>\n\n<h2 id=\"acting-on-the-code-under-test\">Acting on the code-under-test<\/h2>\n\n<p>This has always struck me as a weird way to describe \"executing the\ncode we are testing\" but I guess \"Arrange-Execute-Assert\" doesn't\nflow in English quite the same way.<\/p>\n\n<p>Now that I have all my dependencies created and configured the way\nI need, time to run the code and grab some results I can test.<\/p>\n\n<pre><code class=\"php\">    \/** @test *\/\n    public function it_returns_expected_rotation(): void\n    {\n        \/\/ Arrange\n\n        \/\/ Act\n        $query = new RotationManagementQuery($twig, $gamesRepo, $viewModel);\n        $results = $query-&gt;__invoke($request);\n\n        \/\/ Assert\n        self::fail();\n    }\n<\/code><\/pre>\n\n<h2 id=\"asserting-results-of-code-execution\">Asserting results of code execution<\/h2>\n\n<p>Just like I did before, I am checking the HTML output from executing\nthis Query to make sure I am seeing values that I expect<\/p>\n\n<pre><code class=\"php\">    \/** @test *\/\n    public function it_returns_expected_rotation(): void\n    {\n        \/\/ Arrange\n\n        \/\/ Act\n\n        \/\/ Assert\n        self::assertStringContainsString('One, Two, Three', $results-&gt;getBody());\n    }\n<\/code><\/pre>\n\n<p>When building my assertions, I tend to go with \"what are the\nfewest number of things I need to do in order to prove the\ncode is working as expected.\"<\/p>\n\n<p>In this case, I felt checking that I see an expected \"pitching rotation\"\nin the output is good enough.<\/p>\n\n<p>Here is what the whole test looks like:<\/p>\n\n<pre><code class=\"php\">&lt;?php\n\nnamespace Webreg\\Test\\Query;\n\nuse Doctrine\\Common\\Collections\\ArrayCollection;\nuse Slim\\Psr7\\Request;\nuse Twig\\Environment;\nuse Twig\\Loader\\FilesystemLoader;\nuse Webreg\\Query\\RotationManagementQuery;\nuse PHPUnit\\Framework\\TestCase;\nuse Webreg\\Repository\\GameRepository;\nuse Webreg\\ViewModel\\RotationsUsingDoctrine;\n\nclass RotationManagementQueryTest extends TestCase\n{\n    \/** @test *\/\n    public function it_returns_expected_rotation(): void\n    {\n        \/\/ Arrange\n        $loader = new FilesystemLoader(__DIR__ . '\/..\/..\/templates\/');\n        $twig = new Environment($loader);\n\n        $gamesRepo = $this-&gt;createMock(GameRepository::class);\n        $gamesRepo-&gt;expects($this-&gt;once())\n            -&gt;method('getMaxWeek')\n            -&gt;willReturn(1);\n\n        $testRotation = new ArrayCollection();\n        $testRotation-&gt;add([\n            'franchise_id' =&gt; 1,\n            'ibl' =&gt; 'MAD',\n            'rotation' =&gt; 'One, Two, Three'\n        ]);\n\n        $viewModel = $this-&gt;createMock(RotationsUsingDoctrine::class);\n        $viewModel-&gt;expects($this-&gt;once())\n            -&gt;method('getAllByWeek')\n            -&gt;willReturn($testRotation);\n\n        $request = $this-&gt;createMock(Request::class);\n        $request-&gt;expects($this-&gt;once())\n            -&gt;method('getQueryParams')\n            -&gt;willReturn(['week' =&gt; 1]);\n\n        \/\/ Act\n        $query = new RotationManagementQuery($twig, $gamesRepo, $viewModel);\n        $results = $query-&gt;__invoke($request);\n\n        \/\/ Assert\n        self::assertStringContainsString('One, Two, Three', $results-&gt;getBody());\n    }\n}\n\n<\/code><\/pre>\n\n<p>Some thoughts that occur to me from looking at the final test:<\/p>\n\n<ul>\n<li>decoupling makes your dependencies quite visible during test creation<\/li>\n<li>always make sure to only implement the behaviour of your test doubles that you need<\/li>\n<li>your Arrange step will almost always be the largest part of any test<\/li>\n<li>PHPUnit's built-in test double generators also act as assertions<\/li>\n<li>sometimes the simplest way of verifying behaviour is what you should use<\/li>\n<\/ul>\n\n<p>From my perspective, decoupling the code allows me to focus on smaller\npieces of application behaviour, reducing the chances that a change in\nthis code breaks something somewhere else.<\/p>\n\n<p>For more details on the approach I am using for decoupling my code, check\nout Matthias Noback's <a href=\"https:\/\/leanpub.com\/recipes-for-decoupling\">\"Recipes for Decoupling\"<\/a>.<\/p>\n",
        "date": "2022-12-06T00:00:00+00:00",
        "site": null,
        "tags": null,
        "title": "Testing decoupled PHP code?",
        "uri": "https:\/\/grumpy-learning.com\/blog\/2022\/12\/06\/testing-decoupled-code\/"
    },
    {
        "author": null,
        "categories": [
            "testing"
        ],
        "content": "<p>Over on Twitter Mathias Verraes tweeted something that immediately \ntriggered some feelings:<\/p>\n\n<blockquote>\n  <blockquote>\n    <p>Perhaps TDD isn't as ubiquitous as it should be because you\n    can't make a business model out of it.\n    (Original post on Twitter <a href=\"https:\/\/twitter.com\/mathiasverraes\/status\/1595100145129263106\">https:\/\/twitter.com\/mathiasverraes\/status\/1595100145129263106<\/a><\/p>\n  <\/blockquote>\n<\/blockquote>\n\n<p>I commented saying \"Boy do I ever have feelings about this topic...\" and\nMatias asked me to share. I decided my response was better off as\na longer blog post. Don't worry, this will end up on Twitter \/ Mastodon\nanyway.<\/p>\n\n<p>He mentioned \"observability\" as a technique that ended up\nbeing a very good business model. Why? In my opinion, figuring out\nhow to observe something in production is generic enough in that you\ncan create a tool and say \"hey, add these stuff to your code or\nproduction systems, and it will report stuff to this well-crafted\ndashboard you can use to get an idea of what is going on.\"<\/p>\n\n<p>I am a fan of these approach -- I highly recommend looking into\nthings like <a href=\"https:\/\/www.honeycomb.io\">Honeycomb<\/a> to get an idea\nof what you are signing up for when you choose that path.<\/p>\n\n<p>So what about testing? Is testing generic enough that you could come\nup with some kind of black box or external system that you can connect\nyour tests to and react to when things fail?<\/p>\n\n<p>Tests are almost entirely bespoke. Dependent on architecture. Dependent\non environments. Heck, dependant on the skill of the people who have to\nwrite and maintain them.<\/p>\n\n<p>Also, in my experience, tests work best when you approach them from\nthe idea that they are there to make sure things are behaving as you\nexpect them to and to give you a way to determine if you've made changes\nthat have broken something elsewhere in your application.<\/p>\n\n<p>In other words, chances are that a failing test is something that the\nusers of your application will never notice. They will notice broken\npages, non-functioning links, slow-to-respond interfaces. Those are things\nthat can probably be monitored through observability tools.<\/p>\n\n<p>In a lot of cases you start off with the idea of having to add tests to\na system being adversarial. Developers don't want to spend the time\nwriting them. Management views them as tasks with little-to-no return\non investments. Clients balk at being told your bid is more expensive because\nyou are writing tests. Flaky tests reduce confidence. Build tools need\nto be able to play nicely with your chosen testing tools. Effective\ntest suites can take a lot of time to create and maintain.<\/p>\n\n<p>Not to mention almost nobody teaches people how to learn to use a programming\nlanguage from a test-centric perspective. I could not even imagine\nhow to teach a novice programmer how to use PHP while also showing them\nhow to use all the tools. Understanding my own target audience is developers-with-experience\nhas really changed how I teach and what I teach them.<\/p>\n\n<p>Using an observability tool\ncan often be as simple as signing up for an online tool, follow their\ndirections on what needs to happen to monitor things, and then you\nwill know a lot faster when things aren't behaving correctly in\nproduction.<\/p>\n\n<p>Under those types of terms, testing will never be ubiquitous. Which\nis a shame because it is a technique that can lead to stable code\nbases and confident deployments to production.<\/p>\n\n<p>Maybe someone out there with a different perspective will figure out\nhow to solve the stuff I talked about here. Until then, I am still happy\nto help teach people how to add automated testing to their skill set\nand hope they find it as useful as I have.<\/p>\n",
        "date": "2022-11-22T00:00:00+00:00",
        "site": null,
        "tags": null,
        "title": "Why isn't testing ubiquitous?",
        "uri": "https:\/\/grumpy-learning.com\/blog\/2022\/11\/22\/why-isnt-testing-ubiquitous\/"
    },
    {
        "author": null,
        "categories": [
            "indieweb",
            "technology"
        ],
        "content": "<p>One of the main reasons I have decided to embrace more of\nthe <a href=\"https:\/\/indieweb.org\">IndieWeb<\/a> ethos is out of a desire\nto have more control over where the various things I create\n(micro-blogging and longer-form content) ends up. Twitter ended\nup being something that replaced the blogging I used to do.<\/p>\n\n<p>One of the concepts coming out of the Indieweb is the great-sounding\nacronym POSSE. It stands for Publish On your own Site, Syndicate Elsewhere.\nWhich is another way of saying you should have one central location\nwhere most of your material lives (shitposting on social media still will\nhappen) and then push that content out to other places.<\/p>\n\n<p>So for me, what would this look like?<\/p>\n\n<p>For a long time I had another blog, but once I really leaned into the\nGrumpy Programmer brand that blog served no purpose and I really should've\njust moved stuff over there. Although that old blog is no longer online\nI still have all the posts I made to it. Maybe I will go through one day\nand do \"the best of when I was less grumpy\" or something like that.<\/p>\n\n<p>So, in a world where I embrace POSSE, here is how it should work:<\/p>\n\n<ul>\n<li>I write content on this blog<\/li>\n<li>I use the static site generator <a href=\"https:\/\/sculpin.io\">Sculpin<\/a> to create the site<\/li>\n<li>As part of updating my site, I then automatically publish a link to that blog elsewhere<\/li>\n<\/ul>\n\n<p>There are other solutions to make this happen if you use other blogging\nengines (static or otherwise) but there was nothing out-of-the-box to make it\nwork for Sculpin. So, I used my <a href=\"https:\/\/duckduckgo.com\">favourite search engine<\/a>\nand started doing some research.<\/p>\n\n<p>I also, like any good online influencer, leveraged my personal relationships\nwith people...like the current maintainer of Sculpin...to ask them how I could accomplish\na few tasks.<\/p>\n\n<h2 id=\"writing-on-this-blog\">Writing on this blog<\/h2>\n\n<p>Sculpin supports me writing posts using Markdown. This means I get to keep using\nthe <a href=\"https:\/\/neovim.io\">new One True Editor<\/a> to create new posts. It also uses\n<a href=\"https:\/\/twig.symfony.com\">Twig<\/a> for the templates it uses to generate the static\nHTML for the site.<\/p>\n\n<p>Again, I am not telling you one way or the other what to use for your blog. For a lot\nof folks using <a href=\"https:\/\/wordpress.com\">Wordpress<\/a> and a plugin tailored to IndieWeb\nneeds will work. I didn't want to setup anything new, so I was going to stick with\nSculpin.<\/p>\n\n<h2 id=\"creating-the-site\">Creating the site<\/h2>\n\n<p>I am currently using GitHub pages for this site, so all I have to do is copy the\ngenerated HTML output into the correct location in the repo that holds my site,\npush those changes up to GitHub and in a minute or two I have a new version of\nmy web site for all the world to see.<\/p>\n\n<p>This is no big change for what I was doing previously -- I used to have an AWS\nLightsail instance for hosting the blog but decided GitHub was a better option\nsince I was already paying for an account there. Why pay twice?!?<\/p>\n\n<p>Now, to prepare my site to be \"IndieWeb friendly\" is simply followed the instructions\nat <a href=\"https:\/\/indiewebify.me\">IndeWebify.me<\/a>. Followed by, of course, a lot of\ncommits and pushes to get things to behave exactly the way I needed them to.<\/p>\n\n<p>For example. this is what the template looks like for a blog post, with all the\nIndieWeb <a href=\"https:\/\/microformats.org\/\">microformats<\/a> embedded in them:<\/p>\n\n<pre><code>\n{% extends \"default\" %}\n\n{% block head_meta %}\n    &lt;meta name=\"robots\" content=\"index, follow\"&gt;\n{% endblock %}\n\n{% block content_wrapper %}\n    &lt;article class=\"h-entry\"&gt;\n        &lt;header&gt;\n            &lt;h2&gt;&lt;div class=\"p-name\"&gt;{{ page.title }}&lt;\/div&gt; &lt;small&gt;post&lt;\/small&gt;&lt;\/h2&gt;\n        &lt;\/header&gt;\n        &lt;div class=\"e-content\"&gt;\n            {{ page.blocks.content|raw }}\n        &lt;\/div&gt;\n        {% if page.categories %}\n            &lt;p class=\"categories\"&gt;\n            Categories:\n            {% for category in page.categories %}\n            &lt;a class=\"p-category\" href=\"{{ site.url }}\/blog\/categories\/{{ category|url_encode(true) }}\"&gt;{{ category }}&lt;\/a&gt;{% if not loop.last %}, {% endif %}\n            {% endfor %}\n            &lt;\/p&gt;\n        {% endif %}\n        {% if page.tags %}\n            &lt;p class=\"tags\"&gt;\n            Tags:\n            {% for tag in page.tags %}\n            &lt;a href=\"{{ site.url }}\/blog\/tags\/{{ tag|url_encode(true) }}\"&gt;{{ tag }}&lt;\/a&gt;{% if not loop.last %}, {% endif %}\n            {% endfor %}\n            &lt;\/p&gt;\n        {% endif %}\n        &lt;a href=\"https:\/\/brid.gy\/publish\/mastodon\"&lt;\/a&gt;\n        &lt;a href=\"https:\/\/brid.gy\/publish\/twitter\"&lt;\/a&gt;\n        {% if page.previous_post or page.next_post %}\n            &lt;nav class=\"article\"&gt;\n                &lt;ul&gt;\n                    {% if page.next_post %}\n                        &lt;li&gt;Next: &lt;a class=\"next\" href=\"{{ site.url }}{{ page.next_post.url }}\" title=\"{{ page.next_post.title }}\"&gt;&lt;span class=\"title\"&gt;{{ page.next_post.title }}&lt;\/span&gt;&lt;\/a&gt;&lt;\/li&gt;\n                    {% endif %}\n                    {% if page.previous_post %}\n                        &lt;li&gt;Previous: &lt;a class=\"previous\" href=\"{{ site.url }}{{ page.previous_post.url }}\" title=\"{{ page.previous_post.title }}\"&gt;&lt;span class=\"title\"&gt;{{ page.previous_post.title }}&lt;\/span&gt;&lt;\/a&gt;&lt;\/li&gt;\n                    {% endif %}\n                &lt;\/ul&gt;\n            &lt;\/nav&gt;\n        {% endif %}\n    &lt;\/article&gt;\n{% endblock %}\n\n<\/code><\/pre>\n\n<h2 id=\"the-grumpy-posse\">The Grumpy POSSE<\/h2>\n\n<p>Figuring out how to syndicate my content without an existing plugin proved to\nbe a bit of a challenge. Luckily, I found a blog post that explained how to\nmake this work by embracing <a href=\"https:\/\/indieweb.org\/Webmention\">Webmentions<\/a>\nand using an awesome (and free!) service called <a href=\"https:\/\/brid.gy\">Bridgy<\/a>\nto automate syndication.<\/p>\n\n<p>The solution I found was to create a GitHub action that would be triggered\neach time I did a push to the repo. This action would take care of using\nwebmentions and Brid.gy to do the magic. But first, I needed a feed of\nmy website that was in JSON, not XML.<\/p>\n\n<p>So I hit up <a href=\"https:\/\/phpc.social\/@kboyd\">Kevin Boyd<\/a> and ask him how\ncould I do this in Sculpin. He very gracious created a Twig template\nthat would turn my list of blog posts into a JSON feed. Here it is\nin all it's glory:<\/p>\n\n<pre><code>\n---\npermalink: feed.json\nuse:\n    - posts\n---\n{#\n     Example data structure for delivering a Webmentions feed:\n\n     From: https:\/\/blog.geheimesite.nl\/en\/index.json\n\n     [\n        {\n            \"author\": {},\n            \"categories\": ,\n            \"content\": \"yadda yadda yadda\",\n            \"date\": \"2022-05-03T16:27:18+02:0\",\n            \"site\": \"https:\/\/whateverthing.com\/\",\n            \"tags\": null,\n            \"title\": \"Article One\",\n            \"uri\": \"https:\/\/whateverthing.com\/2022\/11\/11\/article-one\/\"\n        },\n        {\n            \"author\": {},\n            \"categories\": ,\n            \"content\": \"yadda yadda yadda\",\n            \"date\": \"2022-06-03T16:27:18+02:0\",\n            \"site\": \"https:\/\/whateverthing.com\/\",\n            \"tags\": null,\n            \"title\": \"Article Two\",\n            \"uri\": \"https:\/\/whateverthing.com\/2022\/11\/11\/article-two\/\"\n        },\n     ]\n#}\n{% set outputArray = [] %}\n\n{% for post in data.posts[:10] %}\n    {%\n        set postOutput = {\n            'author': site.author,\n            'categories': post.meta.categories,\n            'content': post.blocks.content|raw,\n            'date': post.date|date(\"c\"),\n            'site': site.global_url,\n            'tags': post.meta.tags,\n            'title': post.title,\n            'uri': [ site.global_url, post.url]|join\n        }\n    %}\n    {% set outputArray = outputArray|merge([postOutput]) %}\n{% endfor %}\n\n{{ outputArray|json_encode(constant('JSON_PRETTY_PRINT'))|raw }}\n\n<\/code><\/pre>\n\n<p>I dropped that into the root directory Sculpin uses for generating\nmy site, named it <code>feed.json.twig<\/code> and now I had a JSON-based feed\nfor the site.<\/p>\n\n<p>Now, the GitHub action. This would go in <code>.github\/workflows\/send-webmention.yaml<\/code>\nfor my repo that I am using for the page.<\/p>\n\n<pre><code>name: Send Webmentions\n\non: push\n\njobs:\n  send:\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: Send Webmentions\n        env:\n          GITHUB_TOKEN: $\n          URL: $\n        run: |\n          NEW=$(curl --silent $URL | jq -r first.uri)\n\n          curl -X POST https:\/\/webmention.app\/check?url=\"https:\/\/grumpy.learning.com$NEW\"\n\n          curl -H \"Content-Type: application\/x-www-form-urlencoded\" --request POST \\\n          -d source=\"https:\/\/grumpy-learning.com$NEW\" \\\n          -d target=\"https:\/\/brid.gy\/publish\/twitter\" \\\n          \"https:\/\/brid.gy\/publish\/webmention\"\n\n          curl -H \"Content-Type: application\/x-www-form-urlencoded\" --request POST \\\n          -d source=\"https:\/\/grumpy-learning.com$NEW\" \\\n          -d target=\"https:\/\/brid.gy\/publish\/mastodon\" \\\n          \"https:\/\/brid.gy\/publish\/webmention\"\n<\/code><\/pre>\n\n<p>The <a href=\"https:\/\/gist.github.com\/dianoetic\/b45466a7c04fa47cf80905b182dbda3c\">original instructions<\/a> recommended\nputting the JSON feed details into a secret and then referencing it inside the action.\nI am not sure it matters that much but stuck with it.<\/p>\n\n<p>So, the next thing is that it grabs the feed using <a href=\"https:\/\/curl.se\">cURL<\/a> and grabs what\nit thinks is the latest post (the first one in the feed) and then proceeds to use\n<a href=\"https:\/\/webmention.app\">webmention.app<\/a> and Brid.gy to syndicate my content by sharing\nthe post title and linking to it).<\/p>\n\n<p>So far it is working well and if you came across this post via my social media microblogging (I\nsound so pretentious when I say it out loud) then it clearly worked.<\/p>\n\n<p>I think my takeway from this is that gluing things together so your existing blog\ncan syndicate content to a variety of platforms. If you're looking to have more control over\nthe things you share online, I highly recommend looking into the IndieWeb. I hope this post helps!<\/p>\n",
        "date": "2022-11-18T00:00:00+00:00",
        "site": null,
        "tags": null,
        "title": "A Grumpy POSSE",
        "uri": "https:\/\/grumpy-learning.com\/blog\/2022\/11\/18\/a-grumpy-posse\/"
    },
    {
        "author": null,
        "categories": [
            "indieweb",
            "technology"
        ],
        "content": "<p>As I write this blog post, Twitter is convulsing as it's new\nowner Elon Musk is trying to treat a huge cruise ship like\nit's a jetski. Having cut a ton of staff and literally workshopping\nideas in public, it's not going well.<\/p>\n\n<p>I have ignored blogging and some other interactions as Twitter made\nit so easy to share those little thoughts and I also became reliant\non a curated feed to find stuff I was interested in. Along the way\nI ran into the idea of the <a href=\"https:\/\/indieweb.org\/\">IndieWeb<\/a>.<\/p>\n\n<p>I have made a non-trivial amount of money off selling my <a href=\"https:\/\/leanpub.com\/u\/chartjes\">books<\/a>\nand have dabbled in paid courses and workshops. So it made a lot of\nsense to me to check out this <a href=\"https:\/\/indiewebify.me\">guide to joining the IndieWeb<\/a>\nand learn about <a href=\"https:\/\/microformats.org\">microformats<\/a>, <a href=\"http:\/\/webmention.org\/\">Webmentions<\/a>\nand start really leaning into POSSEing (Publish on my Own Site, Syndicate Elsewhere)\nmy stuff.<\/p>\n\n<p>This is the first blog post that (if I have set up things correctly at my end) that\nwill be syndicated out to other platforms.<\/p>\n",
        "date": "2022-11-12T00:00:00+00:00",
        "site": null,
        "tags": null,
        "title": "Federating Yourself",
        "uri": "https:\/\/grumpy-learning.com\/blog\/2022\/11\/12\/federating-yourself\/"
    },
    {
        "author": null,
        "categories": [
            "development",
            "testing"
        ],
        "content": "<p>This post could also be subtitled \"The Grumpy Programmer's Guide to Getting Rejected at Interviews\".<\/p>\n\n<p>Someone tagged me in a tweet...<\/p>\n\n<blockquote>\n  <p><em>Book idea for @grmpyprogrammer: an interviewing guide for job seekers wanting to get an idea of how dedicated companies are to testing. Questions to ask, ways to gauge the culture, etc.<\/em>\n  <em>(Originally posted on Twitter at <a href=\"https:\/\/twitter.com\/n00bJackleCity\/status\/1481632465403981824?s=20\">https:\/\/twitter.com\/n00bJackleCity\/status\/1481632465403981824?s=20<\/a>)<\/em><\/p>\n<\/blockquote>\n\n<p>...and it got me to thinking about where to start with\na request like this one. My personal opinion that there\nreally isn't a book in here but it did get me to start thinking\nabout what sort of questions you should be asking.<\/p>\n\n<p>Again, keep in mind that all of this is just my opinion. One based\non many years of experience, but still an opinion.<\/p>\n\n<h2 id=\"why-does-it-matter%3F\">Why Does It Matter?<\/h2>\n\n<p>In my experience, companies that make a commitment to doing automated\ntesting also tend to make a commitment towards \"quality\"\nin their coding practices and \"automation\" in their software development tooling.\nThe reason those are in quotes is because they definitely can mean \ndifferent things depending on the company.<\/p>\n\n<p>Now, again, in my experience, you are likely to have more success\nin solving problems and growing your own skills as a developer if you work\nin an environment where they value those things.<\/p>\n\n<p>After all, just because we can get paid a lot of money to dig in the pixel\nmines doesn't mean we should be forced to eat a shit sandwich. We should at \nleast have a choice of the additional toppings.<\/p>\n\n<h2 id=\"what-questions-should-i-ask%3F\">What Questions Should I Ask?<\/h2>\n\n<p>Like a lot of things related to programming, I find it helpful to start at the\nend result you want and work backwards to figure out what needs to be done. Therefore\nI think the first two things to ask are:<\/p>\n\n<blockquote>\n  <blockquote>\n    <p>What things always have to work when you push changes into production\n    and how do you verify that it works as expected?<\/p>\n  <\/blockquote>\n<\/blockquote>\n\n<p>This question cuts to the heart of the issue: what matters and how do we make\nsure it stays that way.<\/p>\n\n<p>What you are looking for is clear statements about what matters and clearer statements\nabout how they verify it. Again, not every company has invested the time and money\ninto having the ability for code changes to seamlessly flow from a development\nenvironment into production, accompanied by effective automated tests and a clear understanding\nof outcomes.<\/p>\n\n<p>If they already have some kind of commitment to testing, asking follow-up questions\nlike this are also very informative:<\/p>\n\n<blockquote>\n  <blockquote>\n    <p>What do you like about your current testing practices and what do you want to change?<\/p>\n  <\/blockquote>\n<\/blockquote>\n\n<p>Pay as much attention to what they like as what they dislike. That will give you an idea\nof what challenges lie ahead if you want to be the person making the changes.<\/p>\n\n<p>Finally, if you want to find out about what their commitment to quality is, I feel like\na great question is:<\/p>\n\n<blockquote>\n  <blockquote>\n    <p>Tell me about how code gets from the developer and up into production<\/p>\n  <\/blockquote>\n<\/blockquote>\n\n<p>Look for things like:<\/p>\n\n<ul>\n<li>code reviews<\/li>\n<li>coding standards<\/li>\n<li>static code analysis<\/li>\n<li>continuous integration systems<\/li>\n<li>separate staging and production environments<\/li>\n<li>automated deployments<\/li>\n<\/ul>\n\n<p>Not all of these things are going to guarantee great results (nothing\ndoes and never believe anyone who says it) but, when taken together,\nthey show a commitment to making sure that:<\/p>\n\n<ul>\n<li>the intent of code is clear<\/li>\n<li>others can understand the code<\/li>\n<li>the code is taking advantage of appropriate language features<\/li>\n<li>the team uses tooling that integrates with version control to automate error-prone manual checklists<\/li>\n<li>application \/ end-to-end testing happens before it reaches production<\/li>\n<li>repeatable processes ensure consistency<\/li>\n<\/ul>\n\n<h2 id=\"so-now-what%3F\">So Now What?<\/h2>\n\n<p>It's hard for me to give any more specific advice other than \"don't be \nafraid to ask more questions based on the answers you are hearing.\" \nIf we're being honest, most companies aren't doing all that stuff I listed\nabove. You can always start at the bottom (\"we try and manually test all changes\")\nand work as hard as you are allowed to on getting to the point where you\nhave an automated test suite catching issues before your users do.<\/p>\n",
        "date": "2022-01-14T00:00:00+00:00",
        "site": null,
        "tags": null,
        "title": "Asking Companies About Testing",
        "uri": "https:\/\/grumpy-learning.com\/blog\/2022\/01\/14\/asking-companies-about-testing\/"
    },
    {
        "author": null,
        "categories": [
            "development",
            "PHP"
        ],
        "content": "<p>I was presented with a problem that was occurring in the <a href=\"https:\/\/grumpy-learning.com\/blog\/2021\/12\/30\/repeatable-dev-environments\/\">virtual machine<\/a>\nI was using for client development work -- the PHP-based acceptance test suite was running\nextremely slowly. Normally it takes 12-13 minutes to run outside of the \nvirtual machine but it was taking...54 minutes!<\/p>\n\n<p>Because I am almost never afraid to ask for help, I bugged <a href=\"https:\/\/twitter.com\/ocramius\">Marco Pivetta<\/a>\nto give me a hand, since he is working on the same client project. I figured if anyone knew of where to START diagnosing what\nthe problem is, it would be Marco.<\/p>\n\n<p>Marco's suggestion after watching a smaller test suite run both in his\nlocal environment and in my VM was that we should run the test suite\nwith a debugger enabled so we can see what is going on terms of resources\nbeing consumed. For PHP, this usually means using <a href=\"https:\/\/xdebug.org\">Xdebug<\/a>.<\/p>\n\n<p>What Xdebug allows you to do is:<\/p>\n\n<ul>\n<li><a href=\"https:\/\/xdebug.org\/docs\/step_debug\">step debugging<\/a><\/li>\n<li>see better <code>var_dump()<\/code> information<\/li>\n<li>write every function call to disk for later summarizing and reporting<\/li>\n<li>profile your code to look for performance bottlenecks<\/li>\n<li>generate code coverage when using PHPUnit (not sure if it works with other testing frameworks)<\/li>\n<\/ul>\n\n<p>I've used the step debugging feature a lot on unfamiliar\ncode bases but the profiling feature was definitely what we needed.<\/p>\n\n<p>To ask Xdebug to profile the code we're testing, you need to have the\nXdebug extension installed and then tell <a href=\"https:\/\/phpunit.de\">PHPUnit<\/a> that you want\nto use it. The command to do it from your shell looks something like\nthis:<\/p>\n\n<p><code>XDEBUG_MODE=profile vendor\/bin\/phpunit --testsuite=unit<\/code><\/p>\n\n<p>Because our test environment was configured to run these tests using a specific\nDocker container, I had to access the container directly via <code>docker-compose exec php-fpm<\/code>\nand then execute this command inside the container.<\/p>\n\n<p>This ran the test suite and generated a large number of <a href=\"https:\/\/valgrind.org\/docs\/manual\/cg-manual.html\">cachegrind<\/a>\nfiles. These files contain profiling data but you need a specialized\ntool to read them and get information out of them that makes sense.\nFor Linux users you would likely want to use <a href=\"https:\/\/kcachegrind.github.io\">KCachegrind<\/a>\nbut luckily for me you can read these files using <a href=\"https:\/\/www.jetbrains.com\/phpstorm\/\">PhpStorm<\/a>.<\/p>\n\n<p>The first step was to figure out which of these cachegrind files to \nexamine. Unfortunately this is more intuition than science: our test\nsuite uses <code>@runInSeparateProcess<\/code> annotations so all the small ones\nrepresent single tests. These are likely not to return any meaningful \ninformation. \"Just pick the biggest one and let's see what happens.\"<\/p>\n\n<p>So, we both opened up cachegrind files of similar sizes and took a look\nat the data. What exactly where we looking for? In terms of bottlenecks\nwe can place things in either \"network\" or \"CPU\" categories. Is the application\nwaiting a lot for external resources (say, a service in a different container)\nor is it waiting for the CPU to finishing doing something before it \ncan continue.<\/p>\n\n<p>Sadly, I cannot share the cachegrind output here as I have NDA's surrounding\nthe client work but the approach was:<\/p>\n\n<ul>\n<li>sort the calls by how much time was being spent on executing them<\/li>\n<li>figure out if it is network or CPU<\/li>\n<\/ul>\n\n<p>For network issues, we were looking for things like time spent connecting\nto a MySQL database in another container. As we scrolled through the list\nat my end together we started noticing a few things:<\/p>\n\n<ul>\n<li>network access wasn't the problem<\/li>\n<li>we were spending an awful lot of time continually parsing a configuration file written using <a href=\"https:\/\/toml.io\/en\/\">TOML<\/a> during bootstrap (ticket filed to fix this)<\/li>\n<li>a lot of very simple PHP calls were taking significant amounts of CPU time<\/li>\n<\/ul>\n\n<p>The next step was to look at how much memory and CPU power I was giving to \nthe virtual machine. I was giving it half my processing cores and half the\navailable memory. So that should not have been an issue.<\/p>\n\n<p>Marco did some searching and found some forum posts of folks complaining about\nhow slow some VM's were in the latest version of <a href=\"https:\/\/www.vmware.com\/products\/fusion.html\">VMWare Fusion<\/a>\nbut their situation didn't seem to be the same as ours.<\/p>\n\n<p>\"Hrm, Chris, open up that 'Advanced Options' section in the 'Processors &amp; Memory' configuration\nsection. Aha!\"<\/p>\n\n<p>In that section were two disabled options, both dealing with running containers\ninside the virtual machine. Given that we are heavily relying on Docker it definitely\nmade sense to enable those.<\/p>\n\n<p>So I shut down the virtual machine, enabled those two options, and started it up.\nMuch to my surprise, the acceptance test suite now ran in 10 minutes instead of\n54 minutes! Huge improvement and is also faster than how long it takes outside\nof the virtual machine.<\/p>\n\n<p>Afterwards, Marco was explaining to me how much Docker relies on having direct memory\naccess to things so not forcing those connections to go through a different path\nin the VM would yield a huge gain. Now I'm happier with the performance of the test\nsuite.<\/p>\n\n<p>So, in summary:<\/p>\n\n<ul>\n<li>the test suite was much slower than expected<\/li>\n<li>a decision was made to run the test suite with Xdebug profiling enabled<\/li>\n<li>we made an educated guess as to which profile output file to analyze<\/li>\n<li>the profiling output led us to believe that there was a CPU-related bottleneck<\/li>\n<li>the virtual machine had adequate memory and processor resources allocated to it<\/li>\n<li>the VM was not configured to run containerized applications optimally<\/li>\n<li>the VM has stopped and options pertaining to running containers inside the VM were enabled<\/li>\n<li>re-running the test suite saw a huge increase in performance and execution time<\/li>\n<\/ul>\n\n<p>Without the ability to profile the code to get a better idea of where there might \nbe problems, it would've taken a lot longer to come to an effective solution.<\/p>\n",
        "date": "2022-01-05T00:00:00+00:00",
        "site": null,
        "tags": null,
        "title": "Solving Problems With Profiling",
        "uri": "https:\/\/grumpy-learning.com\/blog\/2022\/01\/05\/solving-problems-with-profiling\/"
    },
    {
        "author": null,
        "categories": [
            "development",
            "automation",
            "twitter"
        ],
        "content": "<p>I\u2019m not a New Year\u2019s resolution type but here are some suggestions for my fellow devs of things I believe can lead to better outcomes:<\/p>\n\n<p>Learn your IDE\/editor better: I spent a lot of 2021 refining my <a href=\"https:\/\/neovim.org\">Vim<\/a> setup and I plan on adding increased use of <a href=\"https:\/\/vimwiki.github.io\/\">VimWiki<\/a> for making notes and linking things together.<\/p>\n\n<p>If your dynamic language of choice supports types, start using them and <a href=\"https:\/\/psalm.dev\">static<\/a> <a href=\"https:\/\/phpstan.org\">analysis<\/a> tools. It leads to much clearer intent and can catch problems at the edges.<\/p>\n\n<p>Focus on automation. Stop doing things manually the computer can do for you. Take the time to semi-automate manual processes first. It frees your brain up to solve different problems.<\/p>\n\n<p>Make continuous learning a foundation of everything you do. Even after 23 years of getting paid to program, I learn new things almost every day.<\/p>\n\n<p>Remember that what people call \u201cluck\u201d is often you having the skills to take advantage of an opportunity.<\/p>\n\n<p>(This was originally posted as a Twitter thread starting with <a href=\"https:\/\/twitter.com\/grmpyprogrammer\/status\/1477326886766362626\">https:\/\/twitter.com\/grmpyprogrammer\/status\/1477326886766362626<\/a>)<\/p>\n",
        "date": "2022-01-02T00:00:00+00:00",
        "site": null,
        "tags": null,
        "title": "Better Outcomes",
        "uri": "https:\/\/grumpy-learning.com\/blog\/2022\/01\/02\/better-outcomes\/"
    },
    {
        "author": null,
        "categories": [
            "development",
            "automation"
        ],
        "content": "<p>If you have used <a href=\"https:\/\/docker.com\">Docker<\/a> on a Mac\nlaptop, you have likely ran into the \"crossing file systems\"\nissue that can lead to really poor performance in your containers.\nThis becomes frustrating if you are recreating a development environment \nfor applications that rely on a lot of services (micro or otherwise)\n to run. If you are a Windows or Linux user, this sort of thing is pretty much\na non-issue.<\/p>\n\n<p>It seemed like I had two choices on how to potentially deal with this.\nChoice number one was to switch to a different operating system (I have been looking\nat <a href=\"https:\/\/frame.work\">Framework<\/a> laptops) but I was (LOL) grumpy about\ngetting a new laptop when the 2020 13\" MacBook pro I have as I write this is only slightly\nmore than a year old. Okay, I could sell it. But that seems like a bunch\nof busy work.<\/p>\n\n<p>The second choice was to see if I could create a development environment\nthat was faster and still allowed me to use Docker, which is 100% a requirement\nfor the client work I am currently doing.<\/p>\n\n<p>In the past, other people online had hinted at the possibility of doing the development\nwork inside a virtual machine. Basically like connecting to another machine\nvia SSH and then doing my work in there. Good thing I am already a member of the \nCult of Vim.<\/p>\n\n<p>Okay, I think I could work with this. The next issue was HOW to do this all. I've played\naround enough with <a href=\"https:\/\/www.vagrantup.com\/\">Vagrant<\/a>, <a href=\"https:\/\/vmware.com\">VMWare<\/a> and\nVirtual Private Servers to know that the steepest part of the curve with using\nthis solution is getting configured and in a state where it useful rather than\na time-sink or a toy.<\/p>\n\n<p>I am always one to extol the virtues of \"better lucky than good\" and I happened to\nstumble across a tweet from Mitchell Hashimoto (one of the creators of Vagrant)\nwhere he talked about how he does all his development work inside a VM running\non a Mac laptop. I can't find the original tweet, but I made a note about it\nand then he did another tweet about it:<\/p>\n\n<blockquote>\n  <p><em>My NixOS configurations for my dev VM setup are finally sanitized and open source. They work for both Intel and Apple Silicon. And I put together a video showing how I setup a new machine!<\/em>\n  (originally posted at <a href=\"https:\/\/twitter.com\/mitchellh\/status\/1452721115009191938\">https:\/\/twitter.com\/mitchellh\/status\/1452721115009191938<\/a>)<\/p>\n<\/blockquote>\n\n<p>In that tweet he also shared a link to a <a href=\"https:\/\/www.youtube.com\/watch?v=ubDMLoWz76U\">YouTube video<\/a> and\nthe <a href=\"https:\/\/github.com\/mitchellh\/nixos-config\">GitHub repo<\/a> that he was publicly sharing\nthat you could use as a template.<\/p>\n\n<p>Again, in a big coincidence, Mr. Hashimoto was also using <a href=\"https:\/\/nixos.org\">NixOS<\/a> as his\nVM's operating system. NixOS is a Linux distribution based on <a href=\"https:\/\/nixos.org\/manual\/nix\/stable\/introduction.html\">Nix package manager<\/a>.\nWhich doesn't mean much if you're not a fan of their approach.<\/p>\n\n<p>The reason to like Nix is that it bills itself as a <em>purely functional package manager<\/em>.\nIf you've ever come across the \"functional style\" of programming then you might know\nhow powerful it is to have code that has no \"side effects\". This means that your\ncode is not doing things like writing to the file system, or updating records in a database.\nIn a functional world (unless the code is supposed return something random) it is easy\nto test code because the same input should always generate the same output.<\/p>\n\n<p>If you apply this to package management, it means your are choosing and installing dependencies\nin such a way that you can isolate them from each other. It can be difficult to have, for example,\ntwo different versions of PHP installed for your use unless you are relying on third party tools\nto keep track of what version should be active.<\/p>\n\n<p>Nix handles this by forcing you to declare any dependencies explicitly. No more\nworrying about globally-installed libraries causing incompatibility problems. \nWant to see if your PHP project runs on 7.4, 8.0, and 8.1? You can do that easily\nwith NixOS and it's tooling.<\/p>\n\n<p>I guess you can tell I am a fan of NixOS and look forward to using it a lot more.<\/p>\n\n<p>The idea from a high level is this: given a NixOS VM running in VMWare (I am using\nVMWare Fusion) it should take less than 10 minutes to create a development\nenvironment configured with my preferred tools installed from scratch.<\/p>\n\n<p>The repo he provides is definitely not ready to go as-is. You will need to modify\na lot of the things in there -- I know I did. It took about a week of poking at it,\ncreating and destroying lots of VM's, and learning how NixOS wants to do things to\nget it to the point where I could get it up and running and actually use it.<\/p>\n\n<p>I ended up removing a bunch of tools that are related to Mitchell's work on Docker\nand added a few things I knew I was going to need for my work with this client. It\nalso took me a while to figure out how to generate a hash for the password for the \nuser account the build-and-configure process can create for you. But in the\nend I had a VM up and running (that I could also SSH into if I wanted to)<\/p>\n\n<p>By default, the VM uses a graphical interface with a <a href=\"https:\/\/i3wm.org\/\">tiling window manager<\/a>\nand you type Command-N on your Mac and it opens up a terminal session in \n<a href=\"https:\/\/sw.kovidgoyal.net\/kitty\/\">Kitty<\/a> and you are ready to go!.<\/p>\n\n<p>I also had modified the configuration to install Docker and the related\ncommand-line tools. Once I cloned the client repo all I had to do was\n<code>make build<\/code> to create the Docker containers the development environment\nneeded and <code>make unit<\/code> to run the unit test suite in less than half the time.<\/p>\n\n<p>So what is the point of doing all this work? Let's go back to my original\nproblem. Running a test suite that used a development environment consisting\nof multiple Docker containers was incredibly slow. Running on my Mac (and giving\nDocker half the cores and half the available memory) it takes about 80 seconds.\nRunning inside a VM that has access to the same resources takes about 35 seconds.<\/p>\n\n<p>If you've never done a development work flow of \"make a change, run a process to \nverify the change works as expected\" for a large chunk of your work day then perhaps\nyou don't think this is a big deal. Every loop also has come context switching\nas you try and figure out what happened. If you do this 100 times in a day, you\nprobably want this loop to run as quickly as possible.<\/p>\n\n<p>I don't know if there is a phrase or concept or \"law\" about this sort of perception-versus-reality\nissue, but I find myself wanting to get things done FASTER when the process by\nwhich results are determined gets SLOWER. When my test suite runs in 30 seconds,\nI feel like I have lots of time to solve the problem. When it takes a minute-and-a-half\nI get...anxious? Maybe that's the wrong emotion. I know something takes too long \nwhen I start muttering to myself \"this is taking too <insert preferred swear word> long.\".<\/p>\n\n<p>With the \"happens faster than before\" issue solved, I find the next benefit to be \nas I learn how to use Nix to build repeatable environments, a major mistake can be \nsolved by deleting the VM and trying again. Maybe 20 minutes tops to get back to \nwhere I was. When I mess up my development environment\non my MacBook (OS update or maybe <a href=\"https:\/\/brew.sh\/\">Homebrew<\/a> updates an underlying\ndependency) it can be a whole afternoon spent trying to \"fix whatever I broke.\"<\/p>\n\n<p>It's not clear there will ever be any kind of solution for the \"crossing file systems\"\nissue that leads to Docker performing so poorly. My fellow programmers who are\nrunning the newer MacBooks that use Apple's new chips tell me performance is \nquite good. Spending another CAD$3k so Docker runs faster seems like a waste of \nmoney to me, but that is just a personal opinion.<\/p>\n\n<p>I used to be someone who lived on the bleeding edge when it came to their software.\nAs I got older and grumpier I started to value stability and repeatability in my \nsoftware more. A development environment that can be built using <a href=\"https:\/\/www.gnu.org\/software\/make\/\">Make<\/a>\nand a VM is one I can rely on to start me off at a known point, exhibiting\nbehaviour I am expecting. Almost like the benefits of a test suite!<\/p>\n\n<p>Doing this NixOS-in-a-VM stuff relies on you having some experience with Linux \nenvironments. I did run Linux as my desktop environment for several years \nbefore I started buying Apple hardware (which I've done since 2002) and \nMacOS's \"<a href=\"https:\/\/en.wikipedia.org\/wiki\/Berkeley_Software_Distribution\">BSD<\/a> with a pretty window manager\" approach also let me use those\ncommand-line skills.<\/p>\n\n<p>I highly recommend watching Mitchell's YouTube video as he explains how the\nwhole process works. I found it useful because he explains the philosophy of \nhis approach. Understanding WHY someone does things can often lead you to \nquicker insights as to what needs to change to fit your needs.<\/p>\n\n<p>If you do get it all set up, let me know your experiences. With some effort\nI can probably create a more generic version of my set up and create a GitHub\nrepo with all the files in it.<\/p>\n",
        "date": "2021-12-30T00:00:00+00:00",
        "site": null,
        "tags": null,
        "title": "Repeatable Development Environments",
        "uri": "https:\/\/grumpy-learning.com\/blog\/2021\/12\/30\/repeatable-dev-environments\/"
    }
]