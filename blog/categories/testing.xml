<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Grumpy Learning]]></title>
    <link href="https://grumpy-learning.com/blog/categories/testing.xml" rel="self"/>
    <link href="https://grumpy-learning.com/"/>
    <updated>2022-11-22T18:47:15+00:00</updated>
    <id>https://grumpy-learning.com/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[Why isn&#039;t testing ubiquitous?]]></title>
            <link href="https://grumpy-learning.com/blog/2022/11/22/why-isnt-testing-ubiquitous/"/>
            <updated>2022-11-22T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/11/22/why-isnt-testing-ubiquitous/</id>
            <content type="html"><![CDATA[<p>Over on Twitter Mathias Verraes tweeted something that immediately 
triggered some feelings:</p>

<blockquote>
  <blockquote>
    <p>Perhaps TDD isn't as ubiquitous as it should be because you
    can't make a business model out of it.
    (Original post on Twitter <a href="https://twitter.com/mathiasverraes/status/1595100145129263106">https://twitter.com/mathiasverraes/status/1595100145129263106</a></p>
  </blockquote>
</blockquote>

<p>I commented saying "Boy do I ever have feelings about this topic..." and
Matias asked me to share. I decided my response was better off as
a longer blog post. Don't worry, this will end up on Twitter / Mastodon
anyway.</p>

<p>He mentioned "observability" as a technique that ended up
being a very good business model. Why? In my opinion, figuring out
how to observe something in production is generic enough in that you
can create a tool and say "hey, add these stuff to your code or
production systems, and it will report stuff to this well-crafted
dashboard you can use to get an idea of what is going on."</p>

<p>I am a fan of these approach -- I highly recommend looking into
things like <a href="https://www.honeycomb.io">Honeycomb</a> to get an idea
of what you are signing up for when you choose that path.</p>

<p>So what about testing? Is testing generic enough that you could come
up with some kind of black box or external system that you can connect
your tests to and react to when things fail?</p>

<p>Tests are almost entirely bespoke. Dependent on architecture. Dependent
on environments. Heck, dependant on the skill of the people who have to
write and maintain them.</p>

<p>Also, in my experience, tests work best when you approach them from
the idea that they are there to make sure things are behaving as you
expect them to and to give you a way to determine if you've made changes
that have broken something elsewhere in your application.</p>

<p>In other words, chances are that a failing test is something that the
users of your application will never notice. They will notice broken
pages, non-functioning links, slow-to-respond interfaces. Those are things
that can probably be monitored through observability tools.</p>

<p>In a lot of cases you start off with the idea of having to add tests to
a system being adversarial. Developers don't want to spend the time
writing them. Management views them as tasks with little-to-no return
on investments. Clients balk at being told your bid is more expensive because
you are writing tests. Flaky tests reduce confidence. Build tools need
to be able to play nicely with your chosen testing tools. Effective
test suites can take a lot of time to create and maintain.</p>

<p>Not to mention almost nobody teaches people how to learn to use a programming
language from a test-centric perspective. I could not even imagine
how to teach a novice programmer how to use PHP while also showing them
how to use all the tools. Understanding my own target audience is developers-with-experience
has really changed how I teach and what I teach them.</p>

<p>Using an observability tool
can often be as simple as signing up for an online tool, follow their
directions on what needs to happen to monitor things, and then you
will know a lot faster when things aren't behaving correctly in
production.</p>

<p>Under those types of terms, testing will never be ubiquitous. Which
is a shame because it is a technique that can lead to stable code
bases and confident deployments to production.</p>

<p>Maybe someone out there with a different perspective will figure out
how to solve the stuff I talked about here. Until then, I am still happy
to help teach people how to add automated testing to their skill set
and hope they find it as useful as I have.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Asking Companies About Testing]]></title>
            <link href="https://grumpy-learning.com/blog/2022/01/14/asking-companies-about-testing/"/>
            <updated>2022-01-14T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/01/14/asking-companies-about-testing/</id>
            <content type="html"><![CDATA[<p>This post could also be subtitled "The Grumpy Programmer's Guide to Getting Rejected at Interviews".</p>

<p>Someone tagged me in a tweet...</p>

<blockquote>
  <p><em>Book idea for @grmpyprogrammer: an interviewing guide for job seekers wanting to get an idea of how dedicated companies are to testing. Questions to ask, ways to gauge the culture, etc.</em>
  <em>(Originally posted on Twitter at <a href="https://twitter.com/n00bJackleCity/status/1481632465403981824?s=20">https://twitter.com/n00bJackleCity/status/1481632465403981824?s=20</a>)</em></p>
</blockquote>

<p>...and it got me to thinking about where to start with
a request like this one. My personal opinion that there
really isn't a book in here but it did get me to start thinking
about what sort of questions you should be asking.</p>

<p>Again, keep in mind that all of this is just my opinion. One based
on many years of experience, but still an opinion.</p>

<h2 id="why-does-it-matter%3F">Why Does It Matter?</h2>

<p>In my experience, companies that make a commitment to doing automated
testing also tend to make a commitment towards "quality"
in their coding practices and "automation" in their software development tooling.
The reason those are in quotes is because they definitely can mean 
different things depending on the company.</p>

<p>Now, again, in my experience, you are likely to have more success
in solving problems and growing your own skills as a developer if you work
in an environment where they value those things.</p>

<p>After all, just because we can get paid a lot of money to dig in the pixel
mines doesn't mean we should be forced to eat a shit sandwich. We should at 
least have a choice of the additional toppings.</p>

<h2 id="what-questions-should-i-ask%3F">What Questions Should I Ask?</h2>

<p>Like a lot of things related to programming, I find it helpful to start at the
end result you want and work backwards to figure out what needs to be done. Therefore
I think the first two things to ask are:</p>

<blockquote>
  <blockquote>
    <p>What things always have to work when you push changes into production
    and how do you verify that it works as expected?</p>
  </blockquote>
</blockquote>

<p>This question cuts to the heart of the issue: what matters and how do we make
sure it stays that way.</p>

<p>What you are looking for is clear statements about what matters and clearer statements
about how they verify it. Again, not every company has invested the time and money
into having the ability for code changes to seamlessly flow from a development
environment into production, accompanied by effective automated tests and a clear understanding
of outcomes.</p>

<p>If they already have some kind of commitment to testing, asking follow-up questions
like this are also very informative:</p>

<blockquote>
  <blockquote>
    <p>What do you like about your current testing practices and what do you want to change?</p>
  </blockquote>
</blockquote>

<p>Pay as much attention to what they like as what they dislike. That will give you an idea
of what challenges lie ahead if you want to be the person making the changes.</p>

<p>Finally, if you want to find out about what their commitment to quality is, I feel like
a great question is:</p>

<blockquote>
  <blockquote>
    <p>Tell me about how code gets from the developer and up into production</p>
  </blockquote>
</blockquote>

<p>Look for things like:</p>

<ul>
<li>code reviews</li>
<li>coding standards</li>
<li>static code analysis</li>
<li>continuous integration systems</li>
<li>separate staging and production environments</li>
<li>automated deployments</li>
</ul>

<p>Not all of these things are going to guarantee great results (nothing
does and never believe anyone who says it) but, when taken together,
they show a commitment to making sure that:</p>

<ul>
<li>the intent of code is clear</li>
<li>others can understand the code</li>
<li>the code is taking advantage of appropriate language features</li>
<li>the team uses tooling that integrates with version control to automate error-prone manual checklists</li>
<li>application / end-to-end testing happens before it reaches production</li>
<li>repeatable processes ensure consistency</li>
</ul>

<h2 id="so-now-what%3F">So Now What?</h2>

<p>It's hard for me to give any more specific advice other than "don't be 
afraid to ask more questions based on the answers you are hearing." 
If we're being honest, most companies aren't doing all that stuff I listed
above. You can always start at the bottom ("we try and manually test all changes")
and work as hard as you are allowed to on getting to the point where you
have an automated test suite catching issues before your users do.</p>
]]></content>
        </entry>
    </feed>