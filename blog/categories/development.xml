<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Grumpy Learning]]></title>
    <link href="https://grumpy-learning.com/blog/categories/development.xml" rel="self"/>
    <link href="https://grumpy-learning.com/"/>
    <updated>2024-01-13T18:50:51+00:00</updated>
    <id>https://grumpy-learning.com/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[How A Grumpy Programmer Uses View Models]]></title>
            <link href="https://grumpy-learning.com/blog/2024/01/13/view-models/"/>
            <updated>2024-01-13T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2024/01/13/view-models/</id>
            <content type="html"><![CDATA[<h1 id="how-a-grumpy-programmer-uses-viewmodels">How A Grumpy Programmer Uses ViewModels</h1>

<p>As I've started putting together a talk about <a href="https://en.wikipedia.org/wiki/Command_Query_Responsibility_Segregation">CQRS</a> I noticed that in my own application, I am using
ViewModels in my commands and queries to provide data to
my views.</p>

<p>The purpose of the view model is to sit between our Models
(usually something that talks to a data source) and our views
(usually something that displays data to the screen). As part
of the application architecture I am trying to keep things
separated -- some things should not know about each other.</p>

<p>I discovered the concept of the ViewModel from Matthias Noback's
book "Recipes for Decoupling" where he emphasized the concept
that you should not be passing objects (or anything for that matter)
into your views and templates that they don't need.</p>

<p>There is a whole chapter in this book dedicated to ViewModels. I
can't recommend his book highly enough if you are looking to
create or refactor a project are looking for repeatable processes to keep things
as decoupled as possible.</p>

<p>I think showing how the ViewModel works is best done through
sharing some live, in-production, code with you.</p>

<p>I have a simulation baseball league management application. We
are currently in the middle of our player draft. After some
discussion with the person who handles tracking who was drafted,
I made some changes to the previously-working functionality.
Now I am splitting things into Commands and Queries.</p>

<p>In this case, we have our AssignPlayersToTeamQuery class. This
is a Query, meaning it only reads data and doesn't modify anything.
Here is the code for that Query:</p>

<pre><code class="php">declare(strict_types=1);

namespace Webreg\Query;

use Doctrine\Common\Collections\ArrayCollection;
use Slim\Psr7\Request;
use Slim\Psr7\Response;
use Twig\Environment;
use Webreg\ViewModel\Franchise;
use Webreg\ViewModel\Roster;

final class AssignPlayersToTeamQuery
{
    public function __construct(
        private Environment $twig,
        private Franchise $franchise,
        private Roster $roster
    ) {}

    public function __invoke(Request $request): Response
    {
        $response = new Response(200, null);
        $parsedBody = $request-&gt;getParsedBody();
        $playersToDraft = new ArrayCollection();

        foreach ($parsedBody['draft'] as $playerId =&gt; $v) {
            $playersToDraft-&gt;add($this-&gt;roster-&gt;getPlayerById($playerId));
        }

        $params = [
            'playersToDraft' =&gt; $playersToDraft,
            'franchises' =&gt; $this-&gt;franchise-&gt;getAll(),
            'round' =&gt; $parsedBody['round'],
        ];
        $response-&gt;getBody()
            -&gt;write($this-&gt;twig-&gt;render(
                'draft/assign_players.twig',
                $params
            )
        );

        return $response;
    }
}
</code></pre>

<p>In an architecture where we don't care that much about
separating concerns, I'd either just return whatever
entity or object my database layer returns or just
convert things to arrays. PHP loves arrays.</p>

<p>However, I don't want to use arrays. I prefer to use
objects and collections wherever I can. So instead
I created a View Model. It's job is to talk to the
database layer and then give me something that my view
layer can use with no modification.</p>

<p>The reason to go with this sort of structure is that
it does allow me to replace things behind the scenes
if I ever change the data source or want to create
a fake for testing purposes.</p>

<p>Okay, let's look at the code for the ViewModel. I created an interface
for any ViewModels dealing with Roster objects to use:</p>

<pre><code class="php">declare(strict_types=1);

namespace Webreg\ViewModel;

use Doctrine\Common\Collections\ArrayCollection;

interface Roster
{
    public function getByTeam(string $iblTeam): ArrayCollection;
}
</code></pre>

<p>Then I implemented a version using that interface.</p>

<pre><code class="php">&lt;?php
declare(strict_types=1);

namespace Webreg\ViewModel;

use Doctrine\Common\Collections\ArrayCollection;
use Pest\Support\Arr;
use Webreg\Repository\RosterRepositoryUsingDoctrine;
use Webreg\Repository\TransactionRepositoryUsingDoctrine;

class RosterUsingDoctrine implements Roster
{
    public function __construct(
        private RosterRepositoryUsingDoctrine $rosterRepository,
        private TransactionRepositoryUsingDoctrine $transactionRepository)
    {}

    public function getByTeam(string $iblTeam): ArrayCollection
    {
        $roster = new ArrayCollection();

        $deactivations = $this-&gt;transactionRepository-&gt;getRecentDeactivationsByTeam($iblTeam);
        $battersFromRepo = $this-&gt;rosterRepository-&gt;getBatters($iblTeam);
        $batters = new ArrayCollection();

        /** @var \Webreg\Domain\Roster $batter */
        foreach ($battersFromRepo as $batter) {
            $deactivationDate = null;

            foreach ($deactivations as $deactivation) {
                if (str_contains(trim($deactivation-&gt;getLogEntry()), trim($batter-&gt;getTigName()))) {
                    $deactivationDate = $deactivation-&gt;getTransactionDate()-&gt;format('Y-m-d');
                }
            }

            $batters-&gt;add([
                'id' =&gt; $batter-&gt;getId(),
                'tigName' =&gt; $batter-&gt;getTigName(),
                'comments' =&gt; $batter-&gt;getComments(),
                'status' =&gt; $batter-&gt;getStatus(),
                'deactivationDate' =&gt; $deactivationDate,
                'uncarded' =&gt; $batter-&gt;getUncarded(),
            ]);
        }
        $roster['batters'] = $batters;

        $pitchersFromRepo = $this-&gt;rosterRepository-&gt;getPitchers($iblTeam); 
        $pitchers = new ArrayCollection();

        /** @var \Webreg\Domain\Roster $pitcher */
        foreach ($pitchersFromRepo as $pitcher) {
            $deactivationDate = null;

            foreach ($deactivations as $deactivation) {
                if (str_contains(trim($deactivation-&gt;getLogEntry()), trim($pitcher-&gt;getTigName()))) {
                    $deactivationDate = $deactivation-&gt;getTransactionDate()-&gt;format('Y-m-d');
                }
            }

            $pitchers-&gt;add([
                'id' =&gt; $pitcher-&gt;getId(),
                'tigName' =&gt; $pitcher-&gt;getTigName(),
                'comments' =&gt; $pitcher-&gt;getComments(),
                'status' =&gt; $pitcher-&gt;getStatus(),
                'deactivationDate' =&gt; $deactivationDate,
                'uncarded' =&gt; $pitcher-&gt;getUncarded(),
            ]);
        }
        $roster['pitchers'] = $pitchers;
        $roster['currentSeason'] = $this-&gt;rosterRepository-&gt;getCurrentSeason();
        $roster['previousSeason'] = $roster['currentSeason'] - 1;

        $picks = new ArrayCollection();

        if ($iblTeam !== 'FA') {
            $picksFromRepo = $this-&gt;rosterRepository-&gt;getPicks($iblTeam);

            /** @var \Webreg\Domain\Roster $pick */
            foreach ($picksFromRepo as $pick) {
                $picks-&gt;add([
                    'id' =&gt; $pick-&gt;getId(),
                    'tigName' =&gt; $pick-&gt;getTigName()
                ]);
            }
        }

        $roster['picks'] = $picks;

        return $roster;
    }

    public function getPlayerById(int $playerId): \Webreg\Domain\Roster
    {
        return $this-&gt;rosterRepository-&gt;getById($playerId);
    }
}
</code></pre>

<p>I should probably also add that <code>getPlayerById</code> method to the
interface as that seems to be functionality I would want no
matter what.</p>

<p>So as you can see, the <code>getPlayerById</code> method returns the result
of a call to our Repository object (which is also based off an
interface, with a Doctrine-specific implementation) to get one
<code>Roster</code> object that maps to our domain.</p>

<p>So, now I have a collection full of the players who can be picked
ready to be passed into my view. I am using <a href="https://twig.symfony.com">Twig</a>
for rendering my views. Luckily for me it is smart enough to look
at what I pass into it and figure out if I am iterating over arrays
or objects.</p>

<p>The concept of the ViewModel is not a new one -- most PHP web application
frameworks just don't use them. They instead lean into the convention of "you
can pass whatever the database layer gives you into your templates". Which
is fine! I just wanted more separation.</p>

<p>If I was doing something different, like writing code that returns JSON results,
I could still use the same repository like in my example, but create a View Model
that implements the same interface but just returns JSON instead of ArrayCollections or
a single Domain record.</p>

<p>I know it seems like a minor thing -- how often are you likely
to change database servers or change what a template outputs?
The reason to go down this route is that you are providing
consistency. Rather than just bang out some code and call it
a day, I've followed a plan and the next person who comes
along and needs something different can look and say "oh, I
just need to implement a new type of ViewModel and the rest
of the code won't care".</p>

<p>If you are going to be at phptek in Chicago this spring I
will be talking about ViewModels and CQRS and decoupling
at the event.</p>

<p>I hope this blog post has done the following:</p>

<ul>
<li>helped you understand what a ViewModel is</li>
<li>when you should consider using them</li>
<li>what does a sample implementation of them look like</li>
</ul>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Return on Investment on Updating Dependencies]]></title>
            <link href="https://grumpy-learning.com/blog/2024/01/07/roi-on-updating/"/>
            <updated>2024-01-07T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2024/01/07/roi-on-updating/</id>
            <content type="html"><![CDATA[<h1 id="return-on-investment-on-updating-dependencies">Return on Investment on Updating Dependencies</h1>

<p>This week I came across two separate posts that seem to
defy what a lot of terminally-online PHP developers have
embraced as common practices:</p>

<ul>
<li><a href="https://alexcabal.com/posts/standard-ebooks-and-classic-web-tech">How Standard Ebooks serves millions of requests per month</a></li>
<li><a href="https://github.com/freescout-helpdesk/freescout/wiki/Development-Guide#maintaining-security-and-laravel-no-upgrade-policy">Freescout's Maintaining Security and Laravel No-Upgrade Policy</a></li>
</ul>

<h2 id="building-things-with-boring-technology">Building things with boring technology</h2>

<p>The Ebooks blog post is a great primer on how to build something awesome
that serves the needs of users without relying on new web application
frameworks that have a lot of dependencies and features that you aren't
going to need. A lot of thought clearly went into "how can we provide
our users with value by using the minimum amount of code and system
resources". Definitely an approach more developers should embrace.</p>

<p>It also emphasizes a point I have been trying to make to programmers: the
people who USE your application will absolutely not care what you are building
it with. What you use is an implementation detail, and the biggest problem
you will face is finding people who can continue to use your chosen implementation
details and keep the application going.</p>

<p>I am going to guess that of the most common scripting languages out there,
PHP is one of the easier ways to accomplish this task. A language born of
the web, with a lot of web-centric functionality as part of it's standard
library, can be used by developers who are familiar with how the web actually
works.</p>

<p>Alex Cabal talks about how when he wants to build something for the web, he
reaches for PHP. Setting aside the obvious conclusion that people who know
PHP well don't hesitate to use it, the only point where he seems to deviate
from my own thoughts is on using web application frameworks.</p>

<p>In his post he calls them "scaffolding that he doesn't want to ever see again"
while I feel like they are the foundation on which you will be forced to
build everything else on.</p>

<p>Sure, you can either use the front-controller pattern implemented in a
framework that intercepts each call and figures out what to do next...or
you can tell Apache to do the same thing. Clearly, the Apache approach
is the "old school" way while most frameworks supply a convention you
need to follow.</p>

<p>I also like the imaginative use of Git to replace the "M" part of the
"LAMP stack" (Linux-Apache-MySql-PHP for those not familiar with the term)
and furthermore the use of storing all their data in memory instead
of the file system.</p>

<p>It's very clear that the folks at Standard Ebooks clearly understand both
the domain and the problems they are trying to solve. It's also very clear
that they learned to write PHP code long before the current situation of
two dominant frameworks pushing new ideas.</p>

<p>Boring is good. Boring allows you to go home on time and also find solutions
to your problems that were created a decade ago.</p>

<h2 id="the-costs-of-updating">The costs of updating</h2>

<p>I have two very long-running PHP applications on the web: one was built using
<a href="https://cakephp.org">CakePHP</a> and the other is free-form PHP that I am slowly
migrating towards having some structure using <a href="https://slimframework.com">Slim</a>.
So I am familiar with not only updating the underlying dependencies AND with
having to have enough actual knowledge of how the web works to write code that
does not heavily rely on a framework (side note: I think the <a href="https://php-fig.org">PHP Standards Recommendations Project</a> is an unjustly-maligned resource for building web applications).</p>

<p>The post from the Freescout folks is a slightly different. In it, they boldly
state that they see no need to update the base framework they used to build
the application. They have instead chosen to update "vendor packages" -- meaning
they are patching the original code provided via Composer.</p>

<p>Their reasoning is similar to what the Ebooks folks are thinking -- the constant
reality of having to update your framework components and (possibly) support
libraries is real. Now, I could argue that with a good test suite in place this
does become a non-issue but I do not know the state of the test suite for either
application.</p>

<p>I do know that it certainly feels like more work to go through dependencies
written by other developers and apply your own custom patches to them. Then
you are stuck maintaining your own custom version of your dependencies.</p>

<p>I don't know -- perhaps I am just lazy and I am more than willing to suffer
the pain of upgrading my dependencies for security fixes or new features
the developers of the framework want you to embrace. Good test suites are
the key and in the absence of them, I hesitate to both do the work myself
or trust the folks writing the application I am using that "we haven't had
any security issues".</p>

<p>Agian, much like in the case of Standard Ebooks, my thoughts on the approach
the Freescout team is taking isn't wildly different or even disparaging.
I just prefer to use other tools to let me know when I need to fix a problem.</p>

<h2 id="takeways">Takeways</h2>

<p>First, don't hesitate to build things with "boring" tools that you understand
well. Your users will literally not care.</p>

<p>Second, there are at a high level two "costs" to using a framework you will have to deal
with. The first is how hard is it to embrace the conventions it uses. The
second is how often are you going to have to devote time and effort to
update both the framework and it's dependencies.</p>

<p>Third, tests are a great tool you can use to find out what breaks and/or
no longer works as expected when you update dependencies.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Asking Companies About Testing]]></title>
            <link href="https://grumpy-learning.com/blog/2022/01/14/asking-companies-about-testing/"/>
            <updated>2022-01-14T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/01/14/asking-companies-about-testing/</id>
            <content type="html"><![CDATA[<p>This post could also be subtitled "The Grumpy Programmer's Guide to Getting Rejected at Interviews".</p>

<p>Someone tagged me in a tweet...</p>

<blockquote>
  <p><em>Book idea for @grmpyprogrammer: an interviewing guide for job seekers wanting to get an idea of how dedicated companies are to testing. Questions to ask, ways to gauge the culture, etc.</em>
  <em>(Originally posted on Twitter at <a href="https://twitter.com/n00bJackleCity/status/1481632465403981824?s=20">https://twitter.com/n00bJackleCity/status/1481632465403981824?s=20</a>)</em></p>
</blockquote>

<p>...and it got me to thinking about where to start with
a request like this one. My personal opinion that there
really isn't a book in here but it did get me to start thinking
about what sort of questions you should be asking.</p>

<p>Again, keep in mind that all of this is just my opinion. One based
on many years of experience, but still an opinion.</p>

<h2 id="why-does-it-matter%3F">Why Does It Matter?</h2>

<p>In my experience, companies that make a commitment to doing automated
testing also tend to make a commitment towards "quality"
in their coding practices and "automation" in their software development tooling.
The reason those are in quotes is because they definitely can mean 
different things depending on the company.</p>

<p>Now, again, in my experience, you are likely to have more success
in solving problems and growing your own skills as a developer if you work
in an environment where they value those things.</p>

<p>After all, just because we can get paid a lot of money to dig in the pixel
mines doesn't mean we should be forced to eat a shit sandwich. We should at 
least have a choice of the additional toppings.</p>

<h2 id="what-questions-should-i-ask%3F">What Questions Should I Ask?</h2>

<p>Like a lot of things related to programming, I find it helpful to start at the
end result you want and work backwards to figure out what needs to be done. Therefore
I think the first two things to ask are:</p>

<blockquote>
  <blockquote>
    <p>What things always have to work when you push changes into production
    and how do you verify that it works as expected?</p>
  </blockquote>
</blockquote>

<p>This question cuts to the heart of the issue: what matters and how do we make
sure it stays that way.</p>

<p>What you are looking for is clear statements about what matters and clearer statements
about how they verify it. Again, not every company has invested the time and money
into having the ability for code changes to seamlessly flow from a development
environment into production, accompanied by effective automated tests and a clear understanding
of outcomes.</p>

<p>If they already have some kind of commitment to testing, asking follow-up questions
like this are also very informative:</p>

<blockquote>
  <blockquote>
    <p>What do you like about your current testing practices and what do you want to change?</p>
  </blockquote>
</blockquote>

<p>Pay as much attention to what they like as what they dislike. That will give you an idea
of what challenges lie ahead if you want to be the person making the changes.</p>

<p>Finally, if you want to find out about what their commitment to quality is, I feel like
a great question is:</p>

<blockquote>
  <blockquote>
    <p>Tell me about how code gets from the developer and up into production</p>
  </blockquote>
</blockquote>

<p>Look for things like:</p>

<ul>
<li>code reviews</li>
<li>coding standards</li>
<li>static code analysis</li>
<li>continuous integration systems</li>
<li>separate staging and production environments</li>
<li>automated deployments</li>
</ul>

<p>Not all of these things are going to guarantee great results (nothing
does and never believe anyone who says it) but, when taken together,
they show a commitment to making sure that:</p>

<ul>
<li>the intent of code is clear</li>
<li>others can understand the code</li>
<li>the code is taking advantage of appropriate language features</li>
<li>the team uses tooling that integrates with version control to automate error-prone manual checklists</li>
<li>application / end-to-end testing happens before it reaches production</li>
<li>repeatable processes ensure consistency</li>
</ul>

<h2 id="so-now-what%3F">So Now What?</h2>

<p>It's hard for me to give any more specific advice other than "don't be 
afraid to ask more questions based on the answers you are hearing." 
If we're being honest, most companies aren't doing all that stuff I listed
above. You can always start at the bottom ("we try and manually test all changes")
and work as hard as you are allowed to on getting to the point where you
have an automated test suite catching issues before your users do.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Solving Problems With Profiling]]></title>
            <link href="https://grumpy-learning.com/blog/2022/01/05/solving-problems-with-profiling/"/>
            <updated>2022-01-05T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/01/05/solving-problems-with-profiling/</id>
            <content type="html"><![CDATA[<p>I was presented with a problem that was occurring in the <a href="https://grumpy-learning.com/blog/2021/12/30/repeatable-dev-environments/">virtual machine</a>
I was using for client development work -- the PHP-based acceptance test suite was running
extremely slowly. Normally it takes 12-13 minutes to run outside of the 
virtual machine but it was taking...54 minutes!</p>

<p>Because I am almost never afraid to ask for help, I bugged <a href="https://twitter.com/ocramius">Marco Pivetta</a>
to give me a hand, since he is working on the same client project. I figured if anyone knew of where to START diagnosing what
the problem is, it would be Marco.</p>

<p>Marco's suggestion after watching a smaller test suite run both in his
local environment and in my VM was that we should run the test suite
with a debugger enabled so we can see what is going on terms of resources
being consumed. For PHP, this usually means using <a href="https://xdebug.org">Xdebug</a>.</p>

<p>What Xdebug allows you to do is:</p>

<ul>
<li><a href="https://xdebug.org/docs/step_debug">step debugging</a></li>
<li>see better <code>var_dump()</code> information</li>
<li>write every function call to disk for later summarizing and reporting</li>
<li>profile your code to look for performance bottlenecks</li>
<li>generate code coverage when using PHPUnit (not sure if it works with other testing frameworks)</li>
</ul>

<p>I've used the step debugging feature a lot on unfamiliar
code bases but the profiling feature was definitely what we needed.</p>

<p>To ask Xdebug to profile the code we're testing, you need to have the
Xdebug extension installed and then tell <a href="https://phpunit.de">PHPUnit</a> that you want
to use it. The command to do it from your shell looks something like
this:</p>

<p><code>XDEBUG_MODE=profile vendor/bin/phpunit --testsuite=unit</code></p>

<p>Because our test environment was configured to run these tests using a specific
Docker container, I had to access the container directly via <code>docker-compose exec php-fpm</code>
and then execute this command inside the container.</p>

<p>This ran the test suite and generated a large number of <a href="https://valgrind.org/docs/manual/cg-manual.html">cachegrind</a>
files. These files contain profiling data but you need a specialized
tool to read them and get information out of them that makes sense.
For Linux users you would likely want to use <a href="https://kcachegrind.github.io">KCachegrind</a>
but luckily for me you can read these files using <a href="https://www.jetbrains.com/phpstorm/">PhpStorm</a>.</p>

<p>The first step was to figure out which of these cachegrind files to 
examine. Unfortunately this is more intuition than science: our test
suite uses <code>@runInSeparateProcess</code> annotations so all the small ones
represent single tests. These are likely not to return any meaningful 
information. "Just pick the biggest one and let's see what happens."</p>

<p>So, we both opened up cachegrind files of similar sizes and took a look
at the data. What exactly where we looking for? In terms of bottlenecks
we can place things in either "network" or "CPU" categories. Is the application
waiting a lot for external resources (say, a service in a different container)
or is it waiting for the CPU to finishing doing something before it 
can continue.</p>

<p>Sadly, I cannot share the cachegrind output here as I have NDA's surrounding
the client work but the approach was:</p>

<ul>
<li>sort the calls by how much time was being spent on executing them</li>
<li>figure out if it is network or CPU</li>
</ul>

<p>For network issues, we were looking for things like time spent connecting
to a MySQL database in another container. As we scrolled through the list
at my end together we started noticing a few things:</p>

<ul>
<li>network access wasn't the problem</li>
<li>we were spending an awful lot of time continually parsing a configuration file written using <a href="https://toml.io/en/">TOML</a> during bootstrap (ticket filed to fix this)</li>
<li>a lot of very simple PHP calls were taking significant amounts of CPU time</li>
</ul>

<p>The next step was to look at how much memory and CPU power I was giving to 
the virtual machine. I was giving it half my processing cores and half the
available memory. So that should not have been an issue.</p>

<p>Marco did some searching and found some forum posts of folks complaining about
how slow some VM's were in the latest version of <a href="https://www.vmware.com/products/fusion.html">VMWare Fusion</a>
but their situation didn't seem to be the same as ours.</p>

<p>"Hrm, Chris, open up that 'Advanced Options' section in the 'Processors &amp; Memory' configuration
section. Aha!"</p>

<p>In that section were two disabled options, both dealing with running containers
inside the virtual machine. Given that we are heavily relying on Docker it definitely
made sense to enable those.</p>

<p>So I shut down the virtual machine, enabled those two options, and started it up.
Much to my surprise, the acceptance test suite now ran in 10 minutes instead of
54 minutes! Huge improvement and is also faster than how long it takes outside
of the virtual machine.</p>

<p>Afterwards, Marco was explaining to me how much Docker relies on having direct memory
access to things so not forcing those connections to go through a different path
in the VM would yield a huge gain. Now I'm happier with the performance of the test
suite.</p>

<p>So, in summary:</p>

<ul>
<li>the test suite was much slower than expected</li>
<li>a decision was made to run the test suite with Xdebug profiling enabled</li>
<li>we made an educated guess as to which profile output file to analyze</li>
<li>the profiling output led us to believe that there was a CPU-related bottleneck</li>
<li>the virtual machine had adequate memory and processor resources allocated to it</li>
<li>the VM was not configured to run containerized applications optimally</li>
<li>the VM has stopped and options pertaining to running containers inside the VM were enabled</li>
<li>re-running the test suite saw a huge increase in performance and execution time</li>
</ul>

<p>Without the ability to profile the code to get a better idea of where there might 
be problems, it would've taken a lot longer to come to an effective solution.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Better Outcomes]]></title>
            <link href="https://grumpy-learning.com/blog/2022/01/02/better-outcomes/"/>
            <updated>2022-01-02T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/01/02/better-outcomes/</id>
            <content type="html"><![CDATA[<p>I’m not a New Year’s resolution type but here are some suggestions for my fellow devs of things I believe can lead to better outcomes:</p>

<p>Learn your IDE/editor better: I spent a lot of 2021 refining my <a href="https://neovim.org">Vim</a> setup and I plan on adding increased use of <a href="https://vimwiki.github.io/">VimWiki</a> for making notes and linking things together.</p>

<p>If your dynamic language of choice supports types, start using them and <a href="https://psalm.dev">static</a> <a href="https://phpstan.org">analysis</a> tools. It leads to much clearer intent and can catch problems at the edges.</p>

<p>Focus on automation. Stop doing things manually the computer can do for you. Take the time to semi-automate manual processes first. It frees your brain up to solve different problems.</p>

<p>Make continuous learning a foundation of everything you do. Even after 23 years of getting paid to program, I learn new things almost every day.</p>

<p>Remember that what people call “luck” is often you having the skills to take advantage of an opportunity.</p>

<p>(This was originally posted as a Twitter thread starting with <a href="https://twitter.com/grmpyprogrammer/status/1477326886766362626">https://twitter.com/grmpyprogrammer/status/1477326886766362626</a>)</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Repeatable Development Environments]]></title>
            <link href="https://grumpy-learning.com/blog/2021/12/30/repeatable-dev-environments/"/>
            <updated>2021-12-30T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2021/12/30/repeatable-dev-environments/</id>
            <content type="html"><![CDATA[<p>If you have used <a href="https://docker.com">Docker</a> on a Mac
laptop, you have likely ran into the "crossing file systems"
issue that can lead to really poor performance in your containers.
This becomes frustrating if you are recreating a development environment 
for applications that rely on a lot of services (micro or otherwise)
 to run. If you are a Windows or Linux user, this sort of thing is pretty much
a non-issue.</p>

<p>It seemed like I had two choices on how to potentially deal with this.
Choice number one was to switch to a different operating system (I have been looking
at <a href="https://frame.work">Framework</a> laptops) but I was (LOL) grumpy about
getting a new laptop when the 2020 13" MacBook pro I have as I write this is only slightly
more than a year old. Okay, I could sell it. But that seems like a bunch
of busy work.</p>

<p>The second choice was to see if I could create a development environment
that was faster and still allowed me to use Docker, which is 100% a requirement
for the client work I am currently doing.</p>

<p>In the past, other people online had hinted at the possibility of doing the development
work inside a virtual machine. Basically like connecting to another machine
via SSH and then doing my work in there. Good thing I am already a member of the 
Cult of Vim.</p>

<p>Okay, I think I could work with this. The next issue was HOW to do this all. I've played
around enough with <a href="https://www.vagrantup.com/">Vagrant</a>, <a href="https://vmware.com">VMWare</a> and
Virtual Private Servers to know that the steepest part of the curve with using
this solution is getting configured and in a state where it useful rather than
a time-sink or a toy.</p>

<p>I am always one to extol the virtues of "better lucky than good" and I happened to
stumble across a tweet from Mitchell Hashimoto (one of the creators of Vagrant)
where he talked about how he does all his development work inside a VM running
on a Mac laptop. I can't find the original tweet, but I made a note about it
and then he did another tweet about it:</p>

<blockquote>
  <p><em>My NixOS configurations for my dev VM setup are finally sanitized and open source. They work for both Intel and Apple Silicon. And I put together a video showing how I setup a new machine!</em>
  (originally posted at <a href="https://twitter.com/mitchellh/status/1452721115009191938">https://twitter.com/mitchellh/status/1452721115009191938</a>)</p>
</blockquote>

<p>In that tweet he also shared a link to a <a href="https://www.youtube.com/watch?v=ubDMLoWz76U">YouTube video</a> and
the <a href="https://github.com/mitchellh/nixos-config">GitHub repo</a> that he was publicly sharing
that you could use as a template.</p>

<p>Again, in a big coincidence, Mr. Hashimoto was also using <a href="https://nixos.org">NixOS</a> as his
VM's operating system. NixOS is a Linux distribution based on <a href="https://nixos.org/manual/nix/stable/introduction.html">Nix package manager</a>.
Which doesn't mean much if you're not a fan of their approach.</p>

<p>The reason to like Nix is that it bills itself as a <em>purely functional package manager</em>.
If you've ever come across the "functional style" of programming then you might know
how powerful it is to have code that has no "side effects". This means that your
code is not doing things like writing to the file system, or updating records in a database.
In a functional world (unless the code is supposed return something random) it is easy
to test code because the same input should always generate the same output.</p>

<p>If you apply this to package management, it means your are choosing and installing dependencies
in such a way that you can isolate them from each other. It can be difficult to have, for example,
two different versions of PHP installed for your use unless you are relying on third party tools
to keep track of what version should be active.</p>

<p>Nix handles this by forcing you to declare any dependencies explicitly. No more
worrying about globally-installed libraries causing incompatibility problems. 
Want to see if your PHP project runs on 7.4, 8.0, and 8.1? You can do that easily
with NixOS and it's tooling.</p>

<p>I guess you can tell I am a fan of NixOS and look forward to using it a lot more.</p>

<p>The idea from a high level is this: given a NixOS VM running in VMWare (I am using
VMWare Fusion) it should take less than 10 minutes to create a development
environment configured with my preferred tools installed from scratch.</p>

<p>The repo he provides is definitely not ready to go as-is. You will need to modify
a lot of the things in there -- I know I did. It took about a week of poking at it,
creating and destroying lots of VM's, and learning how NixOS wants to do things to
get it to the point where I could get it up and running and actually use it.</p>

<p>I ended up removing a bunch of tools that are related to Mitchell's work on Docker
and added a few things I knew I was going to need for my work with this client. It
also took me a while to figure out how to generate a hash for the password for the 
user account the build-and-configure process can create for you. But in the
end I had a VM up and running (that I could also SSH into if I wanted to)</p>

<p>By default, the VM uses a graphical interface with a <a href="https://i3wm.org/">tiling window manager</a>
and you type Command-N on your Mac and it opens up a terminal session in 
<a href="https://sw.kovidgoyal.net/kitty/">Kitty</a> and you are ready to go!.</p>

<p>I also had modified the configuration to install Docker and the related
command-line tools. Once I cloned the client repo all I had to do was
<code>make build</code> to create the Docker containers the development environment
needed and <code>make unit</code> to run the unit test suite in less than half the time.</p>

<p>So what is the point of doing all this work? Let's go back to my original
problem. Running a test suite that used a development environment consisting
of multiple Docker containers was incredibly slow. Running on my Mac (and giving
Docker half the cores and half the available memory) it takes about 80 seconds.
Running inside a VM that has access to the same resources takes about 35 seconds.</p>

<p>If you've never done a development work flow of "make a change, run a process to 
verify the change works as expected" for a large chunk of your work day then perhaps
you don't think this is a big deal. Every loop also has come context switching
as you try and figure out what happened. If you do this 100 times in a day, you
probably want this loop to run as quickly as possible.</p>

<p>I don't know if there is a phrase or concept or "law" about this sort of perception-versus-reality
issue, but I find myself wanting to get things done FASTER when the process by
which results are determined gets SLOWER. When my test suite runs in 30 seconds,
I feel like I have lots of time to solve the problem. When it takes a minute-and-a-half
I get...anxious? Maybe that's the wrong emotion. I know something takes too long 
when I start muttering to myself "this is taking too <insert preferred swear word> long.".</p>

<p>With the "happens faster than before" issue solved, I find the next benefit to be 
as I learn how to use Nix to build repeatable environments, a major mistake can be 
solved by deleting the VM and trying again. Maybe 20 minutes tops to get back to 
where I was. When I mess up my development environment
on my MacBook (OS update or maybe <a href="https://brew.sh/">Homebrew</a> updates an underlying
dependency) it can be a whole afternoon spent trying to "fix whatever I broke."</p>

<p>It's not clear there will ever be any kind of solution for the "crossing file systems"
issue that leads to Docker performing so poorly. My fellow programmers who are
running the newer MacBooks that use Apple's new chips tell me performance is 
quite good. Spending another CAD$3k so Docker runs faster seems like a waste of 
money to me, but that is just a personal opinion.</p>

<p>I used to be someone who lived on the bleeding edge when it came to their software.
As I got older and grumpier I started to value stability and repeatability in my 
software more. A development environment that can be built using <a href="https://www.gnu.org/software/make/">Make</a>
and a VM is one I can rely on to start me off at a known point, exhibiting
behaviour I am expecting. Almost like the benefits of a test suite!</p>

<p>Doing this NixOS-in-a-VM stuff relies on you having some experience with Linux 
environments. I did run Linux as my desktop environment for several years 
before I started buying Apple hardware (which I've done since 2002) and 
MacOS's "<a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">BSD</a> with a pretty window manager" approach also let me use those
command-line skills.</p>

<p>I highly recommend watching Mitchell's YouTube video as he explains how the
whole process works. I found it useful because he explains the philosophy of 
his approach. Understanding WHY someone does things can often lead you to 
quicker insights as to what needs to change to fit your needs.</p>

<p>If you do get it all set up, let me know your experiences. With some effort
I can probably create a more generic version of my set up and create a GitHub
repo with all the files in it.</p>
]]></content>
        </entry>
    </feed>