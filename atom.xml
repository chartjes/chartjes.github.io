<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Grumpy Learning]]></title>
    <link href="https://grumpy-learning.com/atom.xml" rel="self"/>
    <link href="https://grumpy-learning.com/"/>
    <updated>2023-02-04T19:55:27+00:00</updated>
    <id>https://grumpy-learning.com/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[Monkey patching in PHP]]></title>
            <link href="https://grumpy-learning.com/blog/2023/01/19/monkeypatching-in-php/"/>
            <updated>2023-01-19T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2023/01/19/monkeypatching-in-php/</id>
            <content type="html"><![CDATA[<h2 id="what-is-monkey-patching%3F">What is monkey patching?</h2>

<p>I first learned about <a href="https://en.wikipedia.org/wiki/Monkey_patch">monkey patching</a> via the Ruby community. Due to how
the language worked, Rubyists tended to override dependencies in their
tests at run-time, rather than using <a href="https://en.wikipedia.org/wiki/Test_double">test doubles</a>.
Personally I find the ability to redefine <em>any</em> part of the language to be interesting. It 
certainly does make testing easier.</p>

<p>Now, PHP doesn't support the sort of <a href="https://en.wikipedia.org/wiki/Metaprogramming">metaprogramming</a> that lends
itself to making monkey patching easy. Sure, you used to be able to use the Runkit extension but
these days, it's not being maintained. So, when we run into a situation where you need to redefine
some functionality at run time, your options are limited.</p>

<h2 id="when-to-use-it%3F">When to use it?</h2>

<p>Like I said before, it can be an alternative to using test doubles. But there are also some
interesting scenarios where, due to both PHP's behaviour and the architecture of an application,
we can make a change at run time.</p>

<p>At my <a href="https://smartours.com">current gig</a> I was adding some functionality
to verify some objects representing the prices of objects are configured
correctly. One of my tests was to ensure that a specific exception was
being triggered, and that meant creating a new exception object that
extended a "loggable" one.</p>

<p>This is code that is being implemented as a <a href="https://wordpress.org/plugins/">plugin</a>
for WordPress and the logging object I needed to use had some very
WordPress-specific functionality in it. But I didn't want to have to use all
the WordPress-specific stack just for this test. On top of this, the logging
object wasn't in a namespace that my <a href="https://phpunit.de">PHPUnit</a> tests could
even see.</p>

<p>So what were my options? My first was to modify the <a href="https://getcomposer.org">Composer</a>
autoloading configuration and add the namespace to it. I then had a way to
"force" logging into "test mode" but I wasn't entirely happy with it. The
tests passed, the exception was being triggered, but I had worries in the back
of my mind about whether or not we'd have to do something to the WordPress
side of the application in order to support this.</p>

<p>A <a href="https://phpc.social/@omerida">co-worker</a> showed me how they were already overriding some things at run-time,
so it was better to go with what was already working. Introducing uncertainty
into our application was not the end goal. Here was their solution:</p>

<p>There was an existing <code>test/bootstrap.php</code> file so it was suggested to add a run-time
check to see if the application was attempting to instantiate our logging
object via an autoloader and then instead tell it to use a different one.</p>

<p>First, a replacement logger was created...</p>

<pre><code class="php">&lt;?php

namespace Smartours\Log;

use Monolog\Handler\NullHandler;
use Monolog\Logger;

class Log
{
    public static function logger(): Logger
    {
        $logger = new Logger('generic');
        $logger-&gt;pushHandler(new NullHandler());

        return $logger;
    }
}

</code></pre>

<p>...and then we just included it in our bootstrap file.</p>

<pre><code>require __DIR__ . '/bootstrap/SmartoursLog.php';
</code></pre>

<p>Now, my code that is calling an exception...that needs that
base <code>Log</code> object...will use my <a href="https://en.m.wikipedia.org/wiki/Mock_object">fake</a>
instead.</p>

<p>The test passes and all is in order again.</p>

<h2 id="what-are-some-alternatives%3F">What are some alternatives?</h2>

<p>In a more testable world, what logging object the code is
expecting to use could be done via a configuration file. We'd
still be creating a fake logger, but the mechanism to load it
would be different. Most "modern" PHP web application frameworks
support the use of <a href="https://en.m.wikipedia.org/wiki/Service_locator_pattern">service locaters</a>
and they can be leveraged to make sure your tests have access
to the dependencies they need.</p>

<p>In the future, if we ever needed to add tests for things like making
sure the message the exception we throw shows up in the correct log
file, this solution will have to adapt to those needs.</p>

<p>As always, everyone's testing situation is different and finding
one that fits your need is more important than being perfect..</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[How a grumpy programmer writes Python IRC bots]]></title>
            <link href="https://grumpy-learning.com/blog/2022/12/31/python-irc-bot/"/>
            <updated>2022-12-31T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/12/31/python-irc-bot/</id>
            <content type="html"><![CDATA[<h2 id="why-python-and-why-irc%3F">Why Python and why IRC?</h2>

<p>My longest-running hobby is being a member of <a href="https://www.ibl.org">tabletop simulation baseball league</a>
that uses dice and cards and charts to determine outcomes. There are a lot
of charts so a signifcant amount of time is spent looking up results that
players haven't memorized.</p>

<p>Our league uses IRC as the way to play the games -- the players connect to
the server we host and then play games out using a bot that rolls dice
and communicating with each other via text. Very old school.</p>

<p>Making things a little more player-friendly will help the league get
team owners up to speed quicker, so naturally I turned to automation
and programming as a way to do it.</p>

<p>I chose Python because it had been a while since I had done <em>anything</em> with
it, so why not sharpen the dull edge of my experience there a little. Thankfully
there are lots of examples on how to work with IRC using just the default
libraries that come with Python. In this case, the server the bot would be
running on runs Python 3.8. I started off with <a href="https://pythonspot.com/building-an-irc-bot/">this blog post</a>
and went from there.</p>

<h2 id="initial-implementation">Initial implementation</h2>

<p>From a high level, we are doing the following</p>

<p>1) connect to the IRC server
2) loop endlessly while grabbing any responses from the server
3) examine those responses for my chosen chartbot trigger
4) if triggered, then look for dice rolls
5) display results in-channel</p>

<p>Now, I am sure there are better implementations for what I am trying
to do here involving more commonly-accepted design patterns. In fact,
the code analysis tools I am using are already complaining that the
<a href="https://en.wikipedia.org/wiki/Cyclomatic_complexity">cyclomatic complexity</a>
is too high.</p>

<p>So, here is an example of what I have been doing</p>

<pre><code class="python">while True:
    text = irc.get_response()

    if "PRIVMSG" in text and ".c ifr" in text:
        details = text.split(' ')
        msgChannel = details[-4].strip()
        batterHand[msgChannel] = details[-1].strip()
        lookForIfrRoll[msgChannel] = "yes"
</code></pre>

<p>An example command that this would look for would be '.c ifr rsp'.
This maps to:</p>

<ul>
<li>.c is "activate chartbot"</li>
<li>ifr is "Infield Range"</li>
<li>rsp is "right-spray hitter", with other options available</li>
</ul>

<p>Early on I realized that I needed to have some kind of "state"
in here because it was a two-step process. Once it knew which
chart it was supposed to refer to, it then needed to wait to
get a die roll. Again, this feels like a brute-force method
but I could not think of any other way. Maybe, again, there
is a better pattern for keeping track of this.</p>

<p>So, having figured out we want to refer to the "infield range chart"
(commonly known as IFR in game terms), we tell the bot "the next roll
in this channel should be checked to see if it works with the IFR chart."</p>

<p>Here is a sample of the code that watches for an IFR roll:</p>

<pre><code class="python">    if "rolled" in text:
        details = text.split(' ')
        msgChannel = details[-4].strip()
        roll = details[-1].strip()

        if (msgChannel in lookForIfrRoll and
                batterHand[msgChannel] in validBatterHand and
                len(roll) == 2):
            irc.send(
                 msgChannel, ifrChart.lookup(batterHand[msgChannel], roll)
            )
            del lookForIfrRoll[msgChannel]
            del batterHand[msgChannel]

</code></pre>

<p>All rolls for the IFR chart will be from 00-99, so we make sure the rollbot
returned something 2 characters in length. We also make sure that the
batter hand type matches our expectations. If that is all good, then
we call an object that contains our chart information, do a lookup, and
then send the results of that lookup into the channel.</p>

<p>Here is a sample of what the IFR chart object looks like:</p>

<pre><code class="python">class IFRChart:
    chart = {}

    def __init__(self):
        self.chart = {
            'lp': {
                "00": "Up the middle P",
                "01": "High chopper P",
                "02": "Line drive P",
                "03": "Down the line 1B",
                "04": "Down the line 1B",
                "05": "Down the line 1B",
                # more results snipped
            }
        }

    def lookup(self, bats, roll):
        return self.chart[bats][roll]

</code></pre>

<p>I will say that creating this chart objects helped me get my muscle
memory for Emacs in a better place. So much cut-and-pasting-and-replacing
of things!</p>

<p>So there you have it, a small example of how I have started writing an
IRC bot that:</p>

<ul>
<li>reads responses for a trigger</li>
<li>figures out what chart to read</li>
<li>waits for a die roll that matches expectations</li>
<li>spits out the lookup result in channel</li>
</ul>

<p>As always, I am happy to get some advice on better ways to refactor
and implement solutions for this code.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Current NeoVim setup]]></title>
            <link href="https://grumpy-learning.com/blog/2022/12/13/current-neovim-setup/"/>
            <updated>2022-12-13T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/12/13/current-neovim-setup/</id>
            <content type="html"><![CDATA[<h2 id="grumpiness-and-neovim">Grumpiness and NeoVim</h2>

<p>I have been a <a href="https://vim.org">Vim</a> user since the early 2000's.
Someone who worked in the same building as me and was also a fellow
Linux user (this was before I had bought my first Macbook) got
to talking with me as I struggled to figure out <a href="https://www.gnu.org/software/emacs/">Emacs</a>
suggested I sit with him for a little bit as he showed me how to
use Vim. Still not sure to this day why it clicked with me but I
have been using it ever since.</p>

<p>In the past few years I have changed which version of Vim I am
using and switched to <a href="https://neovim.io/">NeoVim</a>.</p>

<p>Now, to be transparent, these days I use <a href="https://www.jetbrains.com/phpstorm/">PhpStorm</a>
as my main PHP programming tool and use NeoVim for pretty much everything
else. I do pay for PhpStorm because I think it's important to encourage the creation
of tools for the programming languages I use. If I was still doing a lot of
Python work, I'd be paying for <a href="https://www.jetbrains.com/pycharm/">PyCharm</a>.
I had really good experiences with it while at Mozilla.</p>

<p>Anyway, I still like to keep up with what is going on in the NeoVim "community"
and I am happy to see a vibrant group of people creating plugins and
sharing their knowledge. I wanted to give things with NeoVim and PHP another
spin so it was time to go look at my current setup.</p>

<h2 id="why-do-all-this%3F">Why do all this?</h2>

<p>My goal is to have a Vim experience that matches the way I currently work.
I've been using Vim for so long that there is lots of muscle memory and
I usually enable "Vim mode" in any tools I use. Editing things a "modal way"
has become my default and any tools that don't support doing things that
way slow me down immensely.</p>

<p>So, what do I want out of my NeoVim setup.</p>

<ul>
<li>works well with the languages I will use</li>
<li>allows me to quickly find files</li>
<li>allows me to quickly find source definitions</li>
<li>allows me to quickly find places where code is used</li>
</ul>

<p>Now, of course, PhpStorm does all this but also carries a lot of extra
functionality around with it. Which is fine! But in an era where the tools
we use on desktop operating systems get bigger and bigger and consume more
and more resources, I find something appealing in using tools that take up
as few resources as possible.</p>

<p>I did an older post on my old blog from about a year ago so I will
follow the same structure but I noticed some changes. I'll be going
through my current NeoVim config and filling things in as we go</p>

<pre><code>set nocompatible
syntax on 
set encoding=utf8
filetype off

" Load our plugins
lua require('plugins')
</code></pre>

<p>I am using as much <a href="https://www.lua.org">Lua</a> as I can within NeoVim.
The first few steps here are pretty much standard:</p>

<ul>
<li>you always turn "no compatible" off otherwise lots of things break</li>
<li>I want syntax highlighting by default</li>
<li>I want things to be UTF8</li>
<li>I am going to define my own behaviour for how I want NeoVim to
handle filetypes</li>
</ul>

<h2 id="plugins">Plugins</h2>

<p>My list of plugins:</p>

<pre><code class="lua">  return require('packer').startup(function()
    use 'wbthomason/packer.nvim'
    use 'neovim/nvim-lspconfig'

    -- General plugins
    use 'dracula/vim'
    use 'junegunn/vim-easy-align'
    use {
        'nvim-treesitter/nvim-treesitter',
        run = ':TSUpdate'
    }
    use 'onsails/lspkind-nvim'
    use 'vim-vdebug/vdebug'

    -- See the git status of the current line in the gutter
    use 'airblade/vim-gitgutter'

    --  PHP plugins
    use 'tpope/vim-dispatch'
    use 'StanAngeloff/php.vim'
    use 'stephpy/vim-php-cs-fixer'
    use 'jwalton512/vim-blade'
    use 'noahfrederick/vim-laravel'

    -- Help for vim-laravel
    use 'tpope/vim-projectionist'
    use 'noahfrederick/vim-composer'

    -- Respect .editorconfig files for a project
    use 'editorconfig/editorconfig-vim'

    -- Telescope support
    use 'nvim-lua/plenary.nvim'
    use 'nvim-telescope/telescope.nvim'
    use 'sharkdp/fd'
    use {'nvim-telescope/telescope-fzf-native.nvim', run = 'make' }

    -- LSP support for Typescropt
    use 'jose-elias-alvarez/nvim-lsp-ts-utils'

    -- nvim-cmp support
    use 'hrsh7th/nvim-cmp'
    use 'hrsh7th/cmp-nvim-lsp'
    use 'saadparwaiz1/cmp_luasnip'
    use 'L3MON4D3/LuaSnip'

end)
</code></pre>

<p>I am using <a href="https://github.com/wbthomason/packer.nvim">Packer</a> to
handle installing all my packages. I have commented in places where I
felt that things were not clear, but I guess some further explanations
couldn't hurt.</p>

<ul>
<li>I use the <a href="https://draculatheme.com/vim">Dracula</a> theme</li>
<li>I use <a href="https://github.com/junegunn/vim-easy-align">vim-easy-align</a>
to make it easier to line up blocks of code</li>
<li><a href="https://github.com/airblade/vim-gitgutter">vim-gitgutter</a> shows me
which lines have changed from Git's perspective</li>
<li>I like to respect the
<a href="https://github.com/editorconfig/editorconfig-vim">EditorConfig</a>
settings for a project if they exist</li>
<li><a href="https://github.com/nvim-telescope/telescope.nvim">Telescope</a> 
forms the basis for a lot of fuzzy find functionality</li>
<li>I use <a href="https://github.com/hrsh7th/nvim-cmp">nvim-cmp</a> as my
completion engine (and it plays nicely with Intelephense)</li>
</ul>

<h2 id="more-neovim-settings">More NeoVim Settings</h2>

<pre><code>" Do smart autoindenting
set smartindent
set autoindent

" I like linenumbers, thanks
set number

" set search case to a good configuration http://vim.wikia.com/wiki/Searching
set ignorecase
set smartcase

" I like pretty colours in my terminal
set t_Co=256

" Let's get some good colours in our terminal
let $NVM_TUI_ENABLE_TRUE_COLOR=1
set termguicolors
color dracula 

" We want to use ripgrep for any grep commands
set grepprg='rg'

" Basic configuration options
set tabstop=4
set shiftwidth=4
set softtabstop=0
set smarttab
set expandtab
set wildmenu
set wildmode=list:longest,full
set ttyfast
set showmatch
set hlsearch
set incsearch
set backspace=indent,eol,start

" Make sure we are using the version of Python we want
let g:python3_host_prog = "/opt/homebrew/bin/python3"

" We always want to use UTF-8
set encoding=UTF-8
set fileencoding=UTF-8
</code></pre>

<p>A lot of what is up there is fairly straightforward when it comes to
Vim/NeoVim, so I am not going to go over a lot of them.</p>

<h2 id="lsp-configuration">LSP Configuration</h2>

<p>This is the critical piece for me -- supporting different languages
makes NeoVim so versatile.</p>

<p>In my config I have these two lines:</p>

<pre><code>lua require('lsp-config')
lua require('nvm-cmp')
</code></pre>

<p>and these handle my languages and making sure autocompletion behaves
as I expect.</p>

<pre><code class="lua">--- Configuration for LSP, formatters, and linters.
local nvim_lsp = require("lspconfig")

-- short cut methods.
local t = function(str)
  return vim.api.nvim_replace_termcodes(str, true, true, true)
end

local opts = { noremap=true, silent=true }
vim.api.nvim_set_keymap('n', '&lt;space&gt;e', '&lt;cmd&gt;lua vim.diagnostic.open_float()&lt;CR&gt;', opts)
vim.api.nvim_set_keymap('n', '[d', '&lt;cmd&gt;lua vim.diagnostic.goto_prev()&lt;CR&gt;', opts)
vim.api.nvim_set_keymap('n', ']d', '&lt;cmd&gt;lua vim.diagnostic.goto_next()&lt;CR&gt;', opts)
vim.api.nvim_set_keymap('n', '&lt;space&gt;q', '&lt;cmd&gt;lua vim.diagnostic.setloclist()&lt;CR&gt;', opts)
vim.api.nvim_set_keymap('n', '&lt;space&gt;f', '&lt;cmd&gt;lua vim.lsp.buf.formatting()&lt;CR&gt;', opts)

local on_attach = function(client, bufnr)
  -- Enable completion triggered by &lt;c-x&gt;&lt;c-o&gt;
  vim.api.nvim_buf_set_option(bufnr, 'omnifunc', 'v:lua.vim.lsp.omnifunc')

  -- Mappings.
  -- See `:help vim.lsp.*` for documentation on any of the below functions
  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'gD', '&lt;cmd&gt;lua vim.lsp.buf.declaration()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'gd', '&lt;cmd&gt;lua vim.lsp.buf.definition()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'K', '&lt;cmd&gt;lua vim.lsp.buf.hover()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'gi', '&lt;cmd&gt;lua vim.lsp.buf.implementation()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;C-k&gt;', '&lt;cmd&gt;lua vim.lsp.buf.signature_help()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;wa', '&lt;cmd&gt;lua vim.lsp.buf.add_workspace_folder()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;wr', '&lt;cmd&gt;lua vim.lsp.buf.remove_workspace_folder()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;wl', '&lt;cmd&gt;lua print(vim.inspect(vim.lsp.buf.list_workspace_folders()))&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;D', '&lt;cmd&gt;lua vim.lsp.buf.type_definition()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;rn', '&lt;cmd&gt;lua vim.lsp.buf.rename()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', '&lt;space&gt;ca', '&lt;cmd&gt;lua vim.lsp.buf.code_action()&lt;CR&gt;', opts)
  vim.api.nvim_buf_set_keymap(bufnr, 'n', 'gr', '&lt;cmd&gt;lua vim.lsp.buf.references()&lt;CR&gt;', opts)
end

-- PHP
nvim_lsp.intelephense.setup {
    cmd = { "intelephense", "--stdio" },
    filetypes = { "php" },
}

--- Linter setup
local filetypes = {
  typescript = "eslint",
  typescriptreact = "eslint",
  php = {"phpcs", "psalm"},
}

local linters = {
  phpcs = {
    command = "vendor/bin/phpcs",
    sourceName = "phpcs",
    debounce = 300,
    rootPatterns = {"composer.lock", "vendor", ".git"},
    args = {"--report=emacs", "-s", "-"},
    offsetLine = 0,
    offsetColumn = 0,
    sourceName = "phpcs",
    formatLines = 1,
    formatPattern = {
      "^.*:(\\d+):(\\d+):\\s+(.*)\\s+-\\s+(.*)(\\r|\\n)*$",
      {
        line = 1,
        column = 2,
        message = 4,
        security = 3
      }
    },
    securities = {
      error = "error",
      warning = "warning",
    },
    requiredFiles = {"vendor/bin/phpcs"}
  },
  psalm = {
    command = "./vendor/bin/psalm",
    sourceName = "psalm",
    debounce = 100,
    rootPatterns = {"composer.lock", "vendor", ".git"},
    args = {"--output-format=emacs", "--no-progress"},
    offsetLine = 0,
    offsetColumn = 0,
    sourceName = "psalm",
    formatLines = 1,
    formatPattern = {
      "^[^ =]+ =(\\d+) =(\\d+) =(.*)\\s-\\s(.*)(\\r|\\n)*$",
      {
        line = 1,
        column = 2,
        message = 4,
        security = 3
      }
    },
    securities = {
      error = "error",
      warning = "warning"
    },
    requiredFiles = {"vendor/bin/psalm"}
  }
}

nvim_lsp.diagnosticls.setup {
  on_attach = on_attach,
  filetypes = vim.tbl_keys(filetypes),
  init_options = {
    filetypes = filetypes,
    linters = linters,
  },
}
</code></pre>

<p>A lot of what is in here I simple stole from other people's
configurations but I think most of it should be straightforward to
figure out.</p>

<p>Some highlights from my perspective:</p>

<ul>
<li>you pick which language servers to care about</li>
<li>you map functionality to existing Vim bindings so, again, it behaves
as expected</li>
</ul>

<p>Here is what I have for getting the autocompletion engine working:</p>

<pre><code class="lua">local capabilities = vim.lsp.protocol.make_client_capabilities()

local lspconfig = require('lspconfig')

-- Enable some language servers with the additional completion capabilities offered by nvim-cmp
local servers = { 'intelephense', 'tsserver' }
for _, lsp in ipairs(servers) do
  lspconfig[lsp].setup {
    -- on_attach = my_custom_on_attach,
    capabilities = capabilities,
  }
end

-- luasnip setup
local luasnip = require 'luasnip'

-- nvim-cmp setup
local cmp = require 'cmp'
cmp.setup {
  snippet = {
    expand = function(args)
      require('luasnip').lsp_expand(args.body)
    end,
  },
  mapping = {
    ['&lt;C-p&gt;'] = cmp.mapping.select_prev_item(),
    ['&lt;C-n&gt;'] = cmp.mapping.select_next_item(),
    ['&lt;C-d&gt;'] = cmp.mapping.scroll_docs(-4),
    ['&lt;C-f&gt;'] = cmp.mapping.scroll_docs(4),
    ['&lt;C-Space&gt;'] = cmp.mapping.complete(),
    ['&lt;C-e&gt;'] = cmp.mapping.close(),
    ['&lt;CR&gt;'] = cmp.mapping.confirm {
      behavior = cmp.ConfirmBehavior.Replace,
      select = true,
    },
    ['&lt;Tab&gt;'] = function(fallback)
      if cmp.visible() then
        cmp.select_next_item()
      elseif luasnip.expand_or_jumpable() then
        luasnip.expand_or_jump()
      else
        fallback()
      end
    end,
    ['&lt;S-Tab&gt;'] = function(fallback)
      if cmp.visible() then
        cmp.select_prev_item()
      elseif luasnip.jumpable(-1) then
        luasnip.jump(-1)
      else
        fallback()
      end
    end,
  },
  sources = {
    { name = 'nvim_lsp' },
    { name = 'luasnip' },
  },
}
</code></pre>

<p>Again, more mapping of existing keys to get the plugin to behave as
expected. This sort of thing lies at the very heart of how Vim/NeoVim
plugins do so much work -- they literally alter how the application
behaves by overriding things. Perhaps this is actually a form of
monkey patching? TIME IS A CIRCLE.</p>

<h2 id="key-mappings">Key Mappings</h2>

<pre><code class="vim">" ------------------------------------------------------------------------------
" # Mappings
" ------------------------------------------------------------------------------
" # All of your mappings go in this file! Don't worry about your mappings
" # being separate from related config. Sourcery provides mappings to
" # easily jump between plugin definitions, mappings, and configs.
" #
" # More info: https://github.com/jesseleite/vim-sourcery#jumping-between-files


" ------------------------------------------------------------------------------
" # Example
" ------------------------------------------------------------------------------

" easily switch between vsplit windows
map &lt;Leader&gt;j &lt;C-w&gt;j
map &lt;Leader&gt;k &lt;C-w&gt;k
map &lt;Leader&gt;h &lt;c-w&gt;h
map &lt;Leader&gt;l &lt;c-w&gt;l

" Remove highlighing of search terms
nnoremap &lt;leader&gt;&lt;space&gt; :nohlsearch&lt;CR&gt;

" Mappings for EasyAlign
xmap ga &lt;Plug&gt;(EasyAlign)
nmap ga &lt;Plug&gt;(EasyAlign)

" Use &lt;Tab&gt; and &lt;S-Tab&gt; to navigate through popup menu
inoremap &lt;expr&gt; &lt;Tab&gt;   pumvisible() ? "\&lt;C-n&gt;" : "\&lt;Tab&gt;"
inoremap &lt;expr&gt; &lt;S-Tab&gt; pumvisible() ? "\&lt;C-p&gt;" : "\&lt;S-Tab&gt;"

" Telescope Lua mappings
nnoremap &lt;leader&gt;ff &lt;cmd&gt;lua require('telescope.builtin').find_files()&lt;cr&gt;
nnoremap &lt;leader&gt;fg &lt;cmd&gt;lua require('telescope.builtin').live_grep()&lt;cr&gt;
nnoremap &lt;leader&gt;fb &lt;cmd&gt;lua require('telescope.builtin').buffers()&lt;cr&gt;
nnoremap &lt;leader&gt;fh &lt;cmd&gt;lua require('telescope.builtin').help_tags()&lt;cr&gt;
nnoremap &lt;leader&gt;fr &lt;cmd&gt;lua require('telescope.builtin').lsp_references()&lt;cr&gt;
nnoremap &lt;leader&gt;fd &lt;cmd&gt;lua require('telescope.builtin').lsp_definitions()&lt;cr&gt;
nnoremap &lt;leader&gt;ft &lt;cmd&gt;lua require('telescope.builtin').lsp_type_definitions()&lt;cr&gt;
</code></pre>

<p>No Vim setup is complete without mapping and re-mapping keys in
Vim. The list above mostly focuses on making Telescope friendlier to
use.</p>

<p>So there you have it -- this is my current NeoVim setup. It is more
than sufficient for me to do daily PHP development work. What are some
other things I am looking to integrate into my setup?</p>

<ul>
<li>Make it easier to use <a href="https://xdebug.org">XDebug</a></li>
<li>More refactoring tools (I understand Intelephense can help but I
have also experimented with
<a href="https://github.com/phpactor/phpactor">Phpactor</a></li>
</ul>

<p>As always, I continue to tweak my configuration as I evaluate new
tools or discover new ways of completing old tasks. I hope you find my
setup useful.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Testing decoupled PHP code?]]></title>
            <link href="https://grumpy-learning.com/blog/2022/12/06/testing-decoupled-code/"/>
            <updated>2022-12-06T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/12/06/testing-decoupled-code/</id>
            <content type="html"><![CDATA[<p>One of the reasons many experienced developers encourage the concept of
"decoupling your code" is so that it makes testing your code straightforward.
I wanted to share an example of how I went about writing some tests for
some code that I had refactored from being a tangled spaghetti-like mess.</p>

<p>Here is the code I am looking at, written targeting PHP 8.1.</p>

<pre><code class="php">&lt;?php
declare(strict_types=1);

namespace Webreg\Query;

use Slim\Psr7\Response;
use Slim\Psr7\Request;
use Twig\Environment;
use Webreg\Repository\GameRepository;
use Webreg\ViewModel\Rotations;

final class RotationManagementQuery
{
    public function __construct(
        private Environment $twig,
        private GameRepository $gameRepository,
        private Rotations $rotations
    ) {}

    public function __invoke(Request $request): Response
    {
        $params = $request-&gt;getQueryParams();
        $maxWeek = $this-&gt;gameRepository-&gt;getMaxWeek();
        $week = (isset($params['week'])) ? (int) $params['week'] : $maxWeek;
        $rotations = $this-&gt;rotations-&gt;getAllByWeek($week);
        $response = new Response(200, null);
        $response-&gt;getBody()-&gt;write($this-&gt;twig-&gt;render('rotations/management.twig', [
            'current_week' =&gt; $week,
            'rotations' =&gt; $rotations,
        ]));

        return $response;
    }
}
</code></pre>

<p>I am using <a href="https://www.martinfowler.com/bliki/CQRS.html">Command Query Responsibility Segregation</a> in
this application's architecture, and this bit of code is a Query that will
retrieve a collection of pitchers who will be starting for baseball
teams in my simulation baseball league for a particular week.</p>

<p>In following some rules for decoupling, you can see some of the
following decisions had been made:</p>

<ul>
<li>not extending off of a base class</li>
<li>all dependencies are injected at run time</li>
<li>single-method for the class</li>
</ul>

<h2 id="identifying-dependencies">Identifying Dependencies</h2>

<p>So what are the dependencies I will need?</p>

<ul>
<li>a <a href="https://twig.symfony.com">Twig</a> object</li>
<li>a <a href="https://martinfowler.com/eaaCatalog/repository.html">repository</a> object for retrieving data</li>
<li>a <a href="https://martinfowler.com/eaaDev/PresentationModel.html">view model</a> for presenting the data</li>
<li>an object that contains the HTTP <a href="https://www.php-fig.org/psr/psr-7/">request</a></li>
</ul>

<p>In the old architecture, I was creating those dependencies deep inside the "business logic"
and therefore it was very hard to write anything other than some kind of "check
the HTML output" type of test. Ironically that is what the new test does as well but
this sort of decoupled architecture leads to a much more straightforward test.</p>

<h2 id="identifying-output">Identifying Output</h2>

<p>In these tests, I wanted to make sure that if I had at least one rotation
stored in the database for a particular week, when the page renders I should
see that rotation in the output somewhere.</p>

<h2 id="test-skeleton">Test Skeleton</h2>

<p>As always, I break out the <a href="http://wiki.c2.com/?ArrangeActAssert">Arrange-Act-Assert</a> pattern
to create the skeleton of the test:</p>

<pre><code class="php">    /** @test */
    public function it_returns_expected_rotation(): void
    {
        // Arrange

        // Act

        // Assert
        self::fail();
    }
</code></pre>

<p>Remember, you always want to start with a failing test.</p>

<h2 id="arranging-our-dependencies">Arranging our dependencies</h2>

<p>These days I try and use the fewest number of <a href="https://phpunit.readthedocs.io/en/9.5/test-doubles.html">test doubles</a>
in my test scenarios. Given the dependencies I needed,
I was going to need three "fake" dependencies, configured
to provide only the implementation details required to make
the scenario work.</p>

<p>I don't want to get into a longer discussion on the use of
test doubles except to say that the decoupling strategy
I am using will minimize the chances that any doubles drift
from how the code is actually implemented.</p>

<p>Trust me, I do this for a living!</p>

<pre><code class="php">    /** @test */
    public function it_returns_expected_rotation(): void
    {
        // Arrange
        $loader = new FilesystemLoader(__DIR__ . '/../../templates/');
        $twig = new Environment($loader);

        $gamesRepo = $this-&gt;createMock(GameRepository::class);
        $gamesRepo-&gt;expects($this-&gt;once())
            -&gt;method('getMaxWeek')
            -&gt;willReturn(1);

        $testRotation = new ArrayCollection();
        $testRotation-&gt;add([
            'franchise_id' =&gt; 1,
            'ibl' =&gt; 'MAD',
            'rotation' =&gt; 'One, Two, Three'
        ]);

        $viewModel = $this-&gt;createMock(RotationsUsingDoctrine::class);
        $viewModel-&gt;expects($this-&gt;once())
            -&gt;method('getAllByWeek')
            -&gt;willReturn($testRotation);

        $request = $this-&gt;createMock(Request::class);
        $request-&gt;expects($this-&gt;once())
            -&gt;method('getQueryParams')
            -&gt;willReturn(['week' =&gt; 1]);

        // Act

        // Assert
        self::fail();
    }
</code></pre>

<h2 id="acting-on-the-code-under-test">Acting on the code-under-test</h2>

<p>This has always struck me as a weird way to describe "executing the
code we are testing" but I guess "Arrange-Execute-Assert" doesn't
flow in English quite the same way.</p>

<p>Now that I have all my dependencies created and configured the way
I need, time to run the code and grab some results I can test.</p>

<pre><code class="php">    /** @test */
    public function it_returns_expected_rotation(): void
    {
        // Arrange

        // Act
        $query = new RotationManagementQuery($twig, $gamesRepo, $viewModel);
        $results = $query-&gt;__invoke($request);

        // Assert
        self::fail();
    }
</code></pre>

<h2 id="asserting-results-of-code-execution">Asserting results of code execution</h2>

<p>Just like I did before, I am checking the HTML output from executing
this Query to make sure I am seeing values that I expect</p>

<pre><code class="php">    /** @test */
    public function it_returns_expected_rotation(): void
    {
        // Arrange

        // Act

        // Assert
        self::assertStringContainsString('One, Two, Three', $results-&gt;getBody());
    }
</code></pre>

<p>When building my assertions, I tend to go with "what are the
fewest number of things I need to do in order to prove the
code is working as expected."</p>

<p>In this case, I felt checking that I see an expected "pitching rotation"
in the output is good enough.</p>

<p>Here is what the whole test looks like:</p>

<pre><code class="php">&lt;?php

namespace Webreg\Test\Query;

use Doctrine\Common\Collections\ArrayCollection;
use Slim\Psr7\Request;
use Twig\Environment;
use Twig\Loader\FilesystemLoader;
use Webreg\Query\RotationManagementQuery;
use PHPUnit\Framework\TestCase;
use Webreg\Repository\GameRepository;
use Webreg\ViewModel\RotationsUsingDoctrine;

class RotationManagementQueryTest extends TestCase
{
    /** @test */
    public function it_returns_expected_rotation(): void
    {
        // Arrange
        $loader = new FilesystemLoader(__DIR__ . '/../../templates/');
        $twig = new Environment($loader);

        $gamesRepo = $this-&gt;createMock(GameRepository::class);
        $gamesRepo-&gt;expects($this-&gt;once())
            -&gt;method('getMaxWeek')
            -&gt;willReturn(1);

        $testRotation = new ArrayCollection();
        $testRotation-&gt;add([
            'franchise_id' =&gt; 1,
            'ibl' =&gt; 'MAD',
            'rotation' =&gt; 'One, Two, Three'
        ]);

        $viewModel = $this-&gt;createMock(RotationsUsingDoctrine::class);
        $viewModel-&gt;expects($this-&gt;once())
            -&gt;method('getAllByWeek')
            -&gt;willReturn($testRotation);

        $request = $this-&gt;createMock(Request::class);
        $request-&gt;expects($this-&gt;once())
            -&gt;method('getQueryParams')
            -&gt;willReturn(['week' =&gt; 1]);

        // Act
        $query = new RotationManagementQuery($twig, $gamesRepo, $viewModel);
        $results = $query-&gt;__invoke($request);

        // Assert
        self::assertStringContainsString('One, Two, Three', $results-&gt;getBody());
    }
}

</code></pre>

<p>Some thoughts that occur to me from looking at the final test:</p>

<ul>
<li>decoupling makes your dependencies quite visible during test creation</li>
<li>always make sure to only implement the behaviour of your test doubles that you need</li>
<li>your Arrange step will almost always be the largest part of any test</li>
<li>PHPUnit's built-in test double generators also act as assertions</li>
<li>sometimes the simplest way of verifying behaviour is what you should use</li>
</ul>

<p>From my perspective, decoupling the code allows me to focus on smaller
pieces of application behaviour, reducing the chances that a change in
this code breaks something somewhere else.</p>

<p>For more details on the approach I am using for decoupling my code, check
out Matthias Noback's <a href="https://leanpub.com/recipes-for-decoupling">"Recipes for Decoupling"</a>.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Why isn&#039;t testing ubiquitous?]]></title>
            <link href="https://grumpy-learning.com/blog/2022/11/22/why-isnt-testing-ubiquitous/"/>
            <updated>2022-11-22T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/11/22/why-isnt-testing-ubiquitous/</id>
            <content type="html"><![CDATA[<p>Over on Twitter Mathias Verraes tweeted something that immediately 
triggered some feelings:</p>

<blockquote>
  <blockquote>
    <p>Perhaps TDD isn't as ubiquitous as it should be because you
    can't make a business model out of it.
    (Original post on Twitter <a href="https://twitter.com/mathiasverraes/status/1595100145129263106">https://twitter.com/mathiasverraes/status/1595100145129263106</a></p>
  </blockquote>
</blockquote>

<p>I commented saying "Boy do I ever have feelings about this topic..." and
Matias asked me to share. I decided my response was better off as
a longer blog post. Don't worry, this will end up on Twitter / Mastodon
anyway.</p>

<p>He mentioned "observability" as a technique that ended up
being a very good business model. Why? In my opinion, figuring out
how to observe something in production is generic enough in that you
can create a tool and say "hey, add these stuff to your code or
production systems, and it will report stuff to this well-crafted
dashboard you can use to get an idea of what is going on."</p>

<p>I am a fan of these approach -- I highly recommend looking into
things like <a href="https://www.honeycomb.io">Honeycomb</a> to get an idea
of what you are signing up for when you choose that path.</p>

<p>So what about testing? Is testing generic enough that you could come
up with some kind of black box or external system that you can connect
your tests to and react to when things fail?</p>

<p>Tests are almost entirely bespoke. Dependent on architecture. Dependent
on environments. Heck, dependant on the skill of the people who have to
write and maintain them.</p>

<p>Also, in my experience, tests work best when you approach them from
the idea that they are there to make sure things are behaving as you
expect them to and to give you a way to determine if you've made changes
that have broken something elsewhere in your application.</p>

<p>In other words, chances are that a failing test is something that the
users of your application will never notice. They will notice broken
pages, non-functioning links, slow-to-respond interfaces. Those are things
that can probably be monitored through observability tools.</p>

<p>In a lot of cases you start off with the idea of having to add tests to
a system being adversarial. Developers don't want to spend the time
writing them. Management views them as tasks with little-to-no return
on investments. Clients balk at being told your bid is more expensive because
you are writing tests. Flaky tests reduce confidence. Build tools need
to be able to play nicely with your chosen testing tools. Effective
test suites can take a lot of time to create and maintain.</p>

<p>Not to mention almost nobody teaches people how to learn to use a programming
language from a test-centric perspective. I could not even imagine
how to teach a novice programmer how to use PHP while also showing them
how to use all the tools. Understanding my own target audience is developers-with-experience
has really changed how I teach and what I teach them.</p>

<p>Using an observability tool
can often be as simple as signing up for an online tool, follow their
directions on what needs to happen to monitor things, and then you
will know a lot faster when things aren't behaving correctly in
production.</p>

<p>Under those types of terms, testing will never be ubiquitous. Which
is a shame because it is a technique that can lead to stable code
bases and confident deployments to production.</p>

<p>Maybe someone out there with a different perspective will figure out
how to solve the stuff I talked about here. Until then, I am still happy
to help teach people how to add automated testing to their skill set
and hope they find it as useful as I have.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[A Grumpy POSSE]]></title>
            <link href="https://grumpy-learning.com/blog/2022/11/18/a-grumpy-posse/"/>
            <updated>2022-11-18T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/11/18/a-grumpy-posse/</id>
            <content type="html"><![CDATA[<p>One of the main reasons I have decided to embrace more of
the <a href="https://indieweb.org">IndieWeb</a> ethos is out of a desire
to have more control over where the various things I create
(micro-blogging and longer-form content) ends up. Twitter ended
up being something that replaced the blogging I used to do.</p>

<p>One of the concepts coming out of the Indieweb is the great-sounding
acronym POSSE. It stands for Publish On your own Site, Syndicate Elsewhere.
Which is another way of saying you should have one central location
where most of your material lives (shitposting on social media still will
happen) and then push that content out to other places.</p>

<p>So for me, what would this look like?</p>

<p>For a long time I had another blog, but once I really leaned into the
Grumpy Programmer brand that blog served no purpose and I really should've
just moved stuff over there. Although that old blog is no longer online
I still have all the posts I made to it. Maybe I will go through one day
and do "the best of when I was less grumpy" or something like that.</p>

<p>So, in a world where I embrace POSSE, here is how it should work:</p>

<ul>
<li>I write content on this blog</li>
<li>I use the static site generator <a href="https://sculpin.io">Sculpin</a> to create the site</li>
<li>As part of updating my site, I then automatically publish a link to that blog elsewhere</li>
</ul>

<p>There are other solutions to make this happen if you use other blogging
engines (static or otherwise) but there was nothing out-of-the-box to make it
work for Sculpin. So, I used my <a href="https://duckduckgo.com">favourite search engine</a>
and started doing some research.</p>

<p>I also, like any good online influencer, leveraged my personal relationships
with people...like the current maintainer of Sculpin...to ask them how I could accomplish
a few tasks.</p>

<h2 id="writing-on-this-blog">Writing on this blog</h2>

<p>Sculpin supports me writing posts using Markdown. This means I get to keep using
the <a href="https://neovim.io">new One True Editor</a> to create new posts. It also uses
<a href="https://twig.symfony.com">Twig</a> for the templates it uses to generate the static
HTML for the site.</p>

<p>Again, I am not telling you one way or the other what to use for your blog. For a lot
of folks using <a href="https://wordpress.com">Wordpress</a> and a plugin tailored to IndieWeb
needs will work. I didn't want to setup anything new, so I was going to stick with
Sculpin.</p>

<h2 id="creating-the-site">Creating the site</h2>

<p>I am currently using GitHub pages for this site, so all I have to do is copy the
generated HTML output into the correct location in the repo that holds my site,
push those changes up to GitHub and in a minute or two I have a new version of
my web site for all the world to see.</p>

<p>This is no big change for what I was doing previously -- I used to have an AWS
Lightsail instance for hosting the blog but decided GitHub was a better option
since I was already paying for an account there. Why pay twice?!?</p>

<p>Now, to prepare my site to be "IndieWeb friendly" is simply followed the instructions
at <a href="https://indiewebify.me">IndeWebify.me</a>. Followed by, of course, a lot of
commits and pushes to get things to behave exactly the way I needed them to.</p>

<p>For example. this is what the template looks like for a blog post, with all the
IndieWeb <a href="https://microformats.org/">microformats</a> embedded in them:</p>

<pre><code>
{% extends "default" %}

{% block head_meta %}
    &lt;meta name="robots" content="index, follow"&gt;
{% endblock %}

{% block content_wrapper %}
    &lt;article class="h-entry"&gt;
        &lt;header&gt;
            &lt;h2&gt;&lt;div class="p-name"&gt;{{ page.title }}&lt;/div&gt; &lt;small&gt;post&lt;/small&gt;&lt;/h2&gt;
        &lt;/header&gt;
        &lt;div class="e-content"&gt;
            {{ page.blocks.content|raw }}
        &lt;/div&gt;
        {% if page.categories %}
            &lt;p class="categories"&gt;
            Categories:
            {% for category in page.categories %}
            &lt;a class="p-category" href="{{ site.url }}/blog/categories/{{ category|url_encode(true) }}"&gt;{{ category }}&lt;/a&gt;{% if not loop.last %}, {% endif %}
            {% endfor %}
            &lt;/p&gt;
        {% endif %}
        {% if page.tags %}
            &lt;p class="tags"&gt;
            Tags:
            {% for tag in page.tags %}
            &lt;a href="{{ site.url }}/blog/tags/{{ tag|url_encode(true) }}"&gt;{{ tag }}&lt;/a&gt;{% if not loop.last %}, {% endif %}
            {% endfor %}
            &lt;/p&gt;
        {% endif %}
        &lt;a href="https://brid.gy/publish/mastodon"&lt;/a&gt;
        &lt;a href="https://brid.gy/publish/twitter"&lt;/a&gt;
        {% if page.previous_post or page.next_post %}
            &lt;nav class="article"&gt;
                &lt;ul&gt;
                    {% if page.next_post %}
                        &lt;li&gt;Next: &lt;a class="next" href="{{ site.url }}{{ page.next_post.url }}" title="{{ page.next_post.title }}"&gt;&lt;span class="title"&gt;{{ page.next_post.title }}&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
                    {% endif %}
                    {% if page.previous_post %}
                        &lt;li&gt;Previous: &lt;a class="previous" href="{{ site.url }}{{ page.previous_post.url }}" title="{{ page.previous_post.title }}"&gt;&lt;span class="title"&gt;{{ page.previous_post.title }}&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
                    {% endif %}
                &lt;/ul&gt;
            &lt;/nav&gt;
        {% endif %}
    &lt;/article&gt;
{% endblock %}

</code></pre>

<h2 id="the-grumpy-posse">The Grumpy POSSE</h2>

<p>Figuring out how to syndicate my content without an existing plugin proved to
be a bit of a challenge. Luckily, I found a blog post that explained how to
make this work by embracing <a href="https://indieweb.org/Webmention">Webmentions</a>
and using an awesome (and free!) service called <a href="https://brid.gy">Bridgy</a>
to automate syndication.</p>

<p>The solution I found was to create a GitHub action that would be triggered
each time I did a push to the repo. This action would take care of using
webmentions and Brid.gy to do the magic. But first, I needed a feed of
my website that was in JSON, not XML.</p>

<p>So I hit up <a href="https://phpc.social/@kboyd">Kevin Boyd</a> and ask him how
could I do this in Sculpin. He very gracious created a Twig template
that would turn my list of blog posts into a JSON feed. Here it is
in all it's glory:</p>

<pre><code>
---
permalink: feed.json
use:
    - posts
---
{#
     Example data structure for delivering a Webmentions feed:

     From: https://blog.geheimesite.nl/en/index.json

     [
        {
            "author": {},
            "categories": ,
            "content": "yadda yadda yadda",
            "date": "2022-05-03T16:27:18+02:0",
            "site": "https://whateverthing.com/",
            "tags": null,
            "title": "Article One",
            "uri": "https://whateverthing.com/2022/11/11/article-one/"
        },
        {
            "author": {},
            "categories": ,
            "content": "yadda yadda yadda",
            "date": "2022-06-03T16:27:18+02:0",
            "site": "https://whateverthing.com/",
            "tags": null,
            "title": "Article Two",
            "uri": "https://whateverthing.com/2022/11/11/article-two/"
        },
     ]
#}
{% set outputArray = [] %}

{% for post in data.posts[:10] %}
    {%
        set postOutput = {
            'author': site.author,
            'categories': post.meta.categories,
            'content': post.blocks.content|raw,
            'date': post.date|date("c"),
            'site': site.global_url,
            'tags': post.meta.tags,
            'title': post.title,
            'uri': [ site.global_url, post.url]|join
        }
    %}
    {% set outputArray = outputArray|merge([postOutput]) %}
{% endfor %}

{{ outputArray|json_encode(constant('JSON_PRETTY_PRINT'))|raw }}

</code></pre>

<p>I dropped that into the root directory Sculpin uses for generating
my site, named it <code>feed.json.twig</code> and now I had a JSON-based feed
for the site.</p>

<p>Now, the GitHub action. This would go in <code>.github/workflows/send-webmention.yaml</code>
for my repo that I am using for the page.</p>

<pre><code>name: Send Webmentions

on: push

jobs:
  send:
    runs-on: ubuntu-latest
    steps:

      - name: Send Webmentions
        env:
          GITHUB_TOKEN: $
          URL: $
        run: |
          NEW=$(curl --silent $URL | jq -r first.uri)

          curl -X POST https://webmention.app/check?url="https://grumpy.learning.com$NEW"

          curl -H "Content-Type: application/x-www-form-urlencoded" --request POST \
          -d source="https://grumpy-learning.com$NEW" \
          -d target="https://brid.gy/publish/twitter" \
          "https://brid.gy/publish/webmention"

          curl -H "Content-Type: application/x-www-form-urlencoded" --request POST \
          -d source="https://grumpy-learning.com$NEW" \
          -d target="https://brid.gy/publish/mastodon" \
          "https://brid.gy/publish/webmention"
</code></pre>

<p>The <a href="https://gist.github.com/dianoetic/b45466a7c04fa47cf80905b182dbda3c">original instructions</a> recommended
putting the JSON feed details into a secret and then referencing it inside the action.
I am not sure it matters that much but stuck with it.</p>

<p>So, the next thing is that it grabs the feed using <a href="https://curl.se">cURL</a> and grabs what
it thinks is the latest post (the first one in the feed) and then proceeds to use
<a href="https://webmention.app">webmention.app</a> and Brid.gy to syndicate my content by sharing
the post title and linking to it).</p>

<p>So far it is working well and if you came across this post via my social media microblogging (I
sound so pretentious when I say it out loud) then it clearly worked.</p>

<p>I think my takeway from this is that gluing things together so your existing blog
can syndicate content to a variety of platforms. If you're looking to have more control over
the things you share online, I highly recommend looking into the IndieWeb. I hope this post helps!</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Federating Yourself]]></title>
            <link href="https://grumpy-learning.com/blog/2022/11/12/federating-yourself/"/>
            <updated>2022-11-12T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/11/12/federating-yourself/</id>
            <content type="html"><![CDATA[<p>As I write this blog post, Twitter is convulsing as it's new
owner Elon Musk is trying to treat a huge cruise ship like
it's a jetski. Having cut a ton of staff and literally workshopping
ideas in public, it's not going well.</p>

<p>I have ignored blogging and some other interactions as Twitter made
it so easy to share those little thoughts and I also became reliant
on a curated feed to find stuff I was interested in. Along the way
I ran into the idea of the <a href="https://indieweb.org/">IndieWeb</a>.</p>

<p>I have made a non-trivial amount of money off selling my <a href="https://leanpub.com/u/chartjes">books</a>
and have dabbled in paid courses and workshops. So it made a lot of
sense to me to check out this <a href="https://indiewebify.me">guide to joining the IndieWeb</a>
and learn about <a href="https://microformats.org">microformats</a>, <a href="http://webmention.org/">Webmentions</a>
and start really leaning into POSSEing (Publish on my Own Site, Syndicate Elsewhere)
my stuff.</p>

<p>This is the first blog post that (if I have set up things correctly at my end) that
will be syndicated out to other platforms.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Asking Companies About Testing]]></title>
            <link href="https://grumpy-learning.com/blog/2022/01/14/asking-companies-about-testing/"/>
            <updated>2022-01-14T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/01/14/asking-companies-about-testing/</id>
            <content type="html"><![CDATA[<p>This post could also be subtitled "The Grumpy Programmer's Guide to Getting Rejected at Interviews".</p>

<p>Someone tagged me in a tweet...</p>

<blockquote>
  <p><em>Book idea for @grmpyprogrammer: an interviewing guide for job seekers wanting to get an idea of how dedicated companies are to testing. Questions to ask, ways to gauge the culture, etc.</em>
  <em>(Originally posted on Twitter at <a href="https://twitter.com/n00bJackleCity/status/1481632465403981824?s=20">https://twitter.com/n00bJackleCity/status/1481632465403981824?s=20</a>)</em></p>
</blockquote>

<p>...and it got me to thinking about where to start with
a request like this one. My personal opinion that there
really isn't a book in here but it did get me to start thinking
about what sort of questions you should be asking.</p>

<p>Again, keep in mind that all of this is just my opinion. One based
on many years of experience, but still an opinion.</p>

<h2 id="why-does-it-matter%3F">Why Does It Matter?</h2>

<p>In my experience, companies that make a commitment to doing automated
testing also tend to make a commitment towards "quality"
in their coding practices and "automation" in their software development tooling.
The reason those are in quotes is because they definitely can mean 
different things depending on the company.</p>

<p>Now, again, in my experience, you are likely to have more success
in solving problems and growing your own skills as a developer if you work
in an environment where they value those things.</p>

<p>After all, just because we can get paid a lot of money to dig in the pixel
mines doesn't mean we should be forced to eat a shit sandwich. We should at 
least have a choice of the additional toppings.</p>

<h2 id="what-questions-should-i-ask%3F">What Questions Should I Ask?</h2>

<p>Like a lot of things related to programming, I find it helpful to start at the
end result you want and work backwards to figure out what needs to be done. Therefore
I think the first two things to ask are:</p>

<blockquote>
  <blockquote>
    <p>What things always have to work when you push changes into production
    and how do you verify that it works as expected?</p>
  </blockquote>
</blockquote>

<p>This question cuts to the heart of the issue: what matters and how do we make
sure it stays that way.</p>

<p>What you are looking for is clear statements about what matters and clearer statements
about how they verify it. Again, not every company has invested the time and money
into having the ability for code changes to seamlessly flow from a development
environment into production, accompanied by effective automated tests and a clear understanding
of outcomes.</p>

<p>If they already have some kind of commitment to testing, asking follow-up questions
like this are also very informative:</p>

<blockquote>
  <blockquote>
    <p>What do you like about your current testing practices and what do you want to change?</p>
  </blockquote>
</blockquote>

<p>Pay as much attention to what they like as what they dislike. That will give you an idea
of what challenges lie ahead if you want to be the person making the changes.</p>

<p>Finally, if you want to find out about what their commitment to quality is, I feel like
a great question is:</p>

<blockquote>
  <blockquote>
    <p>Tell me about how code gets from the developer and up into production</p>
  </blockquote>
</blockquote>

<p>Look for things like:</p>

<ul>
<li>code reviews</li>
<li>coding standards</li>
<li>static code analysis</li>
<li>continuous integration systems</li>
<li>separate staging and production environments</li>
<li>automated deployments</li>
</ul>

<p>Not all of these things are going to guarantee great results (nothing
does and never believe anyone who says it) but, when taken together,
they show a commitment to making sure that:</p>

<ul>
<li>the intent of code is clear</li>
<li>others can understand the code</li>
<li>the code is taking advantage of appropriate language features</li>
<li>the team uses tooling that integrates with version control to automate error-prone manual checklists</li>
<li>application / end-to-end testing happens before it reaches production</li>
<li>repeatable processes ensure consistency</li>
</ul>

<h2 id="so-now-what%3F">So Now What?</h2>

<p>It's hard for me to give any more specific advice other than "don't be 
afraid to ask more questions based on the answers you are hearing." 
If we're being honest, most companies aren't doing all that stuff I listed
above. You can always start at the bottom ("we try and manually test all changes")
and work as hard as you are allowed to on getting to the point where you
have an automated test suite catching issues before your users do.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Solving Problems With Profiling]]></title>
            <link href="https://grumpy-learning.com/blog/2022/01/05/solving-problems-with-profiling/"/>
            <updated>2022-01-05T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/01/05/solving-problems-with-profiling/</id>
            <content type="html"><![CDATA[<p>I was presented with a problem that was occurring in the <a href="https://grumpy-learning.com/blog/2021/12/30/repeatable-dev-environments/">virtual machine</a>
I was using for client development work -- the PHP-based acceptance test suite was running
extremely slowly. Normally it takes 12-13 minutes to run outside of the 
virtual machine but it was taking...54 minutes!</p>

<p>Because I am almost never afraid to ask for help, I bugged <a href="https://twitter.com/ocramius">Marco Pivetta</a>
to give me a hand, since he is working on the same client project. I figured if anyone knew of where to START diagnosing what
the problem is, it would be Marco.</p>

<p>Marco's suggestion after watching a smaller test suite run both in his
local environment and in my VM was that we should run the test suite
with a debugger enabled so we can see what is going on terms of resources
being consumed. For PHP, this usually means using <a href="https://xdebug.org">Xdebug</a>.</p>

<p>What Xdebug allows you to do is:</p>

<ul>
<li><a href="https://xdebug.org/docs/step_debug">step debugging</a></li>
<li>see better <code>var_dump()</code> information</li>
<li>write every function call to disk for later summarizing and reporting</li>
<li>profile your code to look for performance bottlenecks</li>
<li>generate code coverage when using PHPUnit (not sure if it works with other testing frameworks)</li>
</ul>

<p>I've used the step debugging feature a lot on unfamiliar
code bases but the profiling feature was definitely what we needed.</p>

<p>To ask Xdebug to profile the code we're testing, you need to have the
Xdebug extension installed and then tell <a href="https://phpunit.de">PHPUnit</a> that you want
to use it. The command to do it from your shell looks something like
this:</p>

<p><code>XDEBUG_MODE=profile vendor/bin/phpunit --testsuite=unit</code></p>

<p>Because our test environment was configured to run these tests using a specific
Docker container, I had to access the container directly via <code>docker-compose exec php-fpm</code>
and then execute this command inside the container.</p>

<p>This ran the test suite and generated a large number of <a href="https://valgrind.org/docs/manual/cg-manual.html">cachegrind</a>
files. These files contain profiling data but you need a specialized
tool to read them and get information out of them that makes sense.
For Linux users you would likely want to use <a href="https://kcachegrind.github.io">KCachegrind</a>
but luckily for me you can read these files using <a href="https://www.jetbrains.com/phpstorm/">PhpStorm</a>.</p>

<p>The first step was to figure out which of these cachegrind files to 
examine. Unfortunately this is more intuition than science: our test
suite uses <code>@runInSeparateProcess</code> annotations so all the small ones
represent single tests. These are likely not to return any meaningful 
information. "Just pick the biggest one and let's see what happens."</p>

<p>So, we both opened up cachegrind files of similar sizes and took a look
at the data. What exactly where we looking for? In terms of bottlenecks
we can place things in either "network" or "CPU" categories. Is the application
waiting a lot for external resources (say, a service in a different container)
or is it waiting for the CPU to finishing doing something before it 
can continue.</p>

<p>Sadly, I cannot share the cachegrind output here as I have NDA's surrounding
the client work but the approach was:</p>

<ul>
<li>sort the calls by how much time was being spent on executing them</li>
<li>figure out if it is network or CPU</li>
</ul>

<p>For network issues, we were looking for things like time spent connecting
to a MySQL database in another container. As we scrolled through the list
at my end together we started noticing a few things:</p>

<ul>
<li>network access wasn't the problem</li>
<li>we were spending an awful lot of time continually parsing a configuration file written using <a href="https://toml.io/en/">TOML</a> during bootstrap (ticket filed to fix this)</li>
<li>a lot of very simple PHP calls were taking significant amounts of CPU time</li>
</ul>

<p>The next step was to look at how much memory and CPU power I was giving to 
the virtual machine. I was giving it half my processing cores and half the
available memory. So that should not have been an issue.</p>

<p>Marco did some searching and found some forum posts of folks complaining about
how slow some VM's were in the latest version of <a href="https://www.vmware.com/products/fusion.html">VMWare Fusion</a>
but their situation didn't seem to be the same as ours.</p>

<p>"Hrm, Chris, open up that 'Advanced Options' section in the 'Processors &amp; Memory' configuration
section. Aha!"</p>

<p>In that section were two disabled options, both dealing with running containers
inside the virtual machine. Given that we are heavily relying on Docker it definitely
made sense to enable those.</p>

<p>So I shut down the virtual machine, enabled those two options, and started it up.
Much to my surprise, the acceptance test suite now ran in 10 minutes instead of
54 minutes! Huge improvement and is also faster than how long it takes outside
of the virtual machine.</p>

<p>Afterwards, Marco was explaining to me how much Docker relies on having direct memory
access to things so not forcing those connections to go through a different path
in the VM would yield a huge gain. Now I'm happier with the performance of the test
suite.</p>

<p>So, in summary:</p>

<ul>
<li>the test suite was much slower than expected</li>
<li>a decision was made to run the test suite with Xdebug profiling enabled</li>
<li>we made an educated guess as to which profile output file to analyze</li>
<li>the profiling output led us to believe that there was a CPU-related bottleneck</li>
<li>the virtual machine had adequate memory and processor resources allocated to it</li>
<li>the VM was not configured to run containerized applications optimally</li>
<li>the VM has stopped and options pertaining to running containers inside the VM were enabled</li>
<li>re-running the test suite saw a huge increase in performance and execution time</li>
</ul>

<p>Without the ability to profile the code to get a better idea of where there might 
be problems, it would've taken a lot longer to come to an effective solution.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Better Outcomes]]></title>
            <link href="https://grumpy-learning.com/blog/2022/01/02/better-outcomes/"/>
            <updated>2022-01-02T00:00:00+00:00</updated>
            <id>https://grumpy-learning.com/blog/2022/01/02/better-outcomes/</id>
            <content type="html"><![CDATA[<p>Im not a New Years resolution type but here are some suggestions for my fellow devs of things I believe can lead to better outcomes:</p>

<p>Learn your IDE/editor better: I spent a lot of 2021 refining my <a href="https://neovim.org">Vim</a> setup and I plan on adding increased use of <a href="https://vimwiki.github.io/">VimWiki</a> for making notes and linking things together.</p>

<p>If your dynamic language of choice supports types, start using them and <a href="https://psalm.dev">static</a> <a href="https://phpstan.org">analysis</a> tools. It leads to much clearer intent and can catch problems at the edges.</p>

<p>Focus on automation. Stop doing things manually the computer can do for you. Take the time to semi-automate manual processes first. It frees your brain up to solve different problems.</p>

<p>Make continuous learning a foundation of everything you do. Even after 23 years of getting paid to program, I learn new things almost every day.</p>

<p>Remember that what people call luck is often you having the skills to take advantage of an opportunity.</p>

<p>(This was originally posted as a Twitter thread starting with <a href="https://twitter.com/grmpyprogrammer/status/1477326886766362626">https://twitter.com/grmpyprogrammer/status/1477326886766362626</a>)</p>
]]></content>
        </entry>
    </feed>